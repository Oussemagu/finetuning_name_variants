{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oussemagu/finetuning_name_variants/blob/prompt-engineering_mistral/gen_prompt_names_last_final_demi_eval_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzEchKDshjWp"
      },
      "source": [
        "#model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJdAFEP244J0",
        "outputId": "fa4bf315-b75b-40c5-9817-5b7a33079325"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistral_inference\n",
            "  Downloading mistral_inference-1.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.30.2)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Collecting fire>=0.6.0 (from mistral_inference)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mistral_common>=1.5.4 (from mistral_inference)\n",
            "  Downloading mistral_common-1.5.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: pillow>=10.3.0 in /usr/local/lib/python3.11/dist-packages (from mistral_inference) (11.1.0)\n",
            "Requirement already satisfied: safetensors>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mistral_inference) (0.5.3)\n",
            "Requirement already satisfied: simple-parsing>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from mistral_inference) (0.1.7)\n",
            "Collecting xformers>=0.0.24 (from mistral_inference)\n",
            "  Downloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.13.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.51)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.28)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.6.0->mistral_inference) (3.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: jsonschema>=4.21.1 in /usr/local/lib/python3.11/dist-packages (from mistral_common>=1.5.4->mistral_inference) (4.23.0)\n",
            "Collecting tiktoken>=0.7.0 (from mistral_common>=1.5.4->mistral_inference)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple-parsing>=0.1.5->mistral_inference) (0.16)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.21.1->mistral_common>=1.5.4->mistral_inference) (0.24.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading mistral_inference-1.6.0-py3-none-any.whl (32 kB)\n",
            "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading mistral_common-1.5.4-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.29.post3-cp311-cp311-manylinux_2_28_x86_64.whl (43.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=aa7077e08c2ef1994c7e1621d0aa99a1ecdd211447475326121cba804438b74c\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mypy-extensions, marshmallow, httpx-sse, fire, typing-inspect, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, nvidia-cusolver-cu12, dataclasses-json, mistral_common, xformers, bitsandbytes, mistral_inference, langchain-community\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.45.5 dataclasses-json-0.6.7 fire-0.7.0 httpx-sse-0.4.0 langchain-community-0.3.21 marshmallow-3.26.1 mistral_common-1.5.4 mistral_inference-1.6.0 mypy-extensions-1.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pydantic-settings-2.8.1 python-dotenv-1.1.0 tiktoken-0.9.0 typing-inspect-0.9.0 xformers-0.0.29.post3\n"
          ]
        }
      ],
      "source": [
        "!pip install mistral_inference transformers sentencepiece accelerate bitsandbytes python-dotenv huggingface_hub langchain-community langchain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJDmsL6m-_c0",
        "outputId": "a09a5c3d-d9a6-431e-c566-972b890b69ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-Levenshtein\n",
            "  Downloading python_levenshtein-0.27.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.3)\n",
            "Collecting Levenshtein==0.27.1 (from python-Levenshtein)\n",
            "  Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.27.1->python-Levenshtein)\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/3d/2c/4b2f8aafdf9400e5599b6ed2f14bc26ca75f5a923571926ccbc998d4246a/rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.30.2)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.51)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.51.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.3.28)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain-huggingface) (1.3.1)\n",
            "Downloading python_levenshtein-0.27.1-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein, langchain-huggingface\n",
            "Successfully installed Levenshtein-0.27.1 langchain-huggingface-0.1.2 python-Levenshtein-0.27.1 rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install python-Levenshtein langchain-huggingface pydantic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kttxdmm98w0W",
        "outputId": "d58b4ac7-6457-4556-a09d-90a811703670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `gen_names` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `gen_names`\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dwEaqLquQvA3"
      },
      "outputs": [],
      "source": [
        "from transformers import LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline\n",
        "import torch\n",
        "\n",
        "from langchain.llms import HuggingFacePipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J3mPrvsZKttR",
        "outputId": "f1af9421-8208-4aae-8743-fbc21af4b0e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;31m# Get the response from http.client.HTTPConnection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1394\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1314\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1167\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: The read operation timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m             resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    668\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    842\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_e\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_method_retryable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/util/util.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;31m# Make the request on the HTTPConnection object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             response = self._make_request(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mBaseSSLError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mread_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_raise_timeout\u001b[0;34m(self, err, url, timeout_value)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSocketTimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             raise ReadTimeoutError(\n\u001b[0m\u001b[1;32m    368\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Read timed out. (read timeout={timeout_value})\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeoutError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mReadTimeout\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1483\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1485\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1400\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1402\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;31m# Perform request and return if status_code is not in the retry list.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    712\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReadTimeoutError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mReadTimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_InvalidHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReadTimeout\u001b[0m: (ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 93bbde24-c4b8-4f41-aafc-85d451ab1c89)')",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# This is slightly better for only 1 file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             hf_hub_download(\n\u001b[0m\u001b[1;32m    425\u001b[0m                 \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         return _hf_hub_download_to_cache_dir(\n\u001b[0m\u001b[1;32m    962\u001b[0m             \u001b[0;31m# Destination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1067\u001b[0m         \u001b[0;31m# Otherwise, raise appropriate error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m         \u001b[0m_raise_on_head_call_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_call_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1598\u001b[0m         \u001b[0;31m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1599\u001b[0;31m         raise LocalEntryNotFoundError(\n\u001b[0m\u001b[1;32m   1600\u001b[0m             \u001b[0;34m\"An error happened while trying to locate the file on the Hub and we cannot find the requested files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-9e110bcb849f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mistralai/Mistral-7B-Instruct-v0.3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\",\n\u001b[1;32m      6\u001b[0m     \u001b[0mload_in_8bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Enable 8-bit quantization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                     config = AutoConfig.from_pretrained(\n\u001b[0m\u001b[1;32m    966\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrust_remote_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 649\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    650\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \"\"\"\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_files\u001b[0;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;31m# even when `local_files_only` is True, in which case raising for connections errors only would not make sense)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0m_raise_exceptions_for_missing_entries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m                 raise OSError(\n\u001b[0m\u001b[1;32m    492\u001b[0m                     \u001b[0;34mf\"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load the files, and couldn't find them in the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                     \u001b[0;34mf\" cached files.\\nCheckout your internet connection or see how to run the library in offline mode at\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load the files, and couldn't find them in the cached files.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
          ]
        }
      ],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
        "    load_in_8bit=True,  # Enable 8-bit quantization\n",
        "    device_map=\"auto\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2jte1nZNqLZ",
        "outputId": "4e23bbc3-3f65-454a-e115-8c97d7a2dabc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "pipe = pipeline(\"text-generation\",\n",
        "                model=model,\n",
        "                tokenizer=tokenizer,\n",
        "                max_new_tokens=512,\n",
        "                temperature=0.7,\n",
        "                do_sample=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNKC_hZvOQDY"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7tbDNw5G5Fx"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "class OrthographicVariations(BaseModel):\n",
        "    Latin: List[str] = Field(description=\"Three distinct Latin script variations\", min_items=3, max_items=3)\n",
        "    Cyrillic: List[str] = Field(description=\"Three distinct Cyrillic script variations\", min_items=3, max_items=3)\n",
        "    Arabic: List[str] = Field(description=\"Three distinct Arabic script variations\", min_items=3, max_items=3)\n",
        "\n",
        "class NameTransliterationOutput(BaseModel):\n",
        "    Orthographic_Variations: OrthographicVariations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByEWipWzVTZT",
        "outputId": "69d67a76-d211-459b-f8e4-a86a2322c33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Input Name: sawsen bent foulenn\n",
            "Output:\n",
            "Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name sawsen bent foulenn.\n",
            "\n",
            "User input name: sawsen bent foulenn\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Sawsen Bent Foulenn\", \"Sawsein Bent Fouleann\", \"Sawsen Bint Fouleinn\"],\n",
            "    \"Cyrillic\": [\"Саузен Бент Фулеен\", \"Саузен Бент Фулеенн\", \"Саузен Бент Фулейн\"],\n",
            "    \"Arabic\": [\"سوسن بنت فولن\", \"سوسن بنت فولنن\", \"سوسن بنت فولين\"]\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import StructuredOutputParser\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.output_parsers import PydanticOutputParser # Updated import\n",
        "\n",
        "output_parser = PydanticOutputParser(pydantic_object=NameTransliterationOutput)\n",
        "# Define the prompt template\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"name\"],\n",
        "    template=\"\"\"\n",
        "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name {name}.\n",
        "\n",
        "User input name: {name}\n",
        "\n",
        "Instructions:\n",
        "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
        "   - Latin\n",
        "   - Cyrillic\n",
        "   - Arabic\n",
        "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
        "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
        "4. Do not invent names or scripts not requested.\n",
        "5. Output the result as a JSON object matching this schema:\n",
        "{output_parser.get_format_instructions}\n",
        "6. Do not include any text outside the JSON object.\n",
        "\n",
        "Examples:\n",
        "1. User input name: Aleksandr Petrov\n",
        "```json\n",
        "   {{\n",
        "  \"Orthographic_Variations\": {{\n",
        "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
        "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
        "    \"Arabic\": [\"ألكسندر بتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
        "  }}\n",
        "}}\n",
        "\n",
        "\n",
        "2. User input name: فاطمة الزهراء\n",
        "   {{\n",
        "  \"Orthographic_Variations\": {{\n",
        "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
        "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
        "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
        "  }}\n",
        "}}\n",
        "\n",
        "3. User input name: Саид Петр\n",
        "   {{\n",
        "  \"Orthographic_Variations\": {{\n",
        "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
        "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
        "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
        "  }}\n",
        "}}\n",
        "[/INST]\n",
        "\"\"\",\n",
        "    partial_variables={\"output_parser\": output_parser}\n",
        ")\n",
        "\n",
        "\n",
        "# Test names\n",
        "test_names = [\"sawsen bent foulenn\"]\n",
        "\n",
        "# Run the prompt for each test name\n",
        "for name in test_names:\n",
        "    formatted_prompt = prompt_template.format(name=name, output_parser=output_parser)\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": formatted_prompt}\n",
        "    ]\n",
        "    print(f\"\\nInput Name: {name}\")\n",
        "    print(\"Output:\")\n",
        "    print(llm.invoke(messages))  # Use invoke for cleaner output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zMCJX8g_Ce-"
      },
      "source": [
        "#evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCuvQkBYgUdT",
        "outputId": "86aa5853-df77-4be6-c77f-e2245df4ddc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/51.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.2)\n",
            "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading portalocker-3.1.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-3.1.1 sacrebleu-2.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5MucrxAro3f",
        "outputId": "5fdc9b70-8cde-4fab-83ff-1dc320c2620c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/187.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/491.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install python-Levenshtein pandas ragas nltk --quiet\n",
        "\n",
        "\n",
        "\n",
        "# Import other modules\n",
        "import json\n",
        "import pandas as pd\n",
        "from Levenshtein import distance\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "from ragas.metrics import BleuScore, AnswerSimilarity\n",
        "from ragas.dataset_schema import SingleTurnSample\n",
        "from ragas.metrics import SemanticSimilarity\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQhAKxuzrsfN",
        "outputId": "2805cc3e-3af6-4454-8f3b-25fa4c194fcc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt', quiet=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUnu1VfBt1oy"
      },
      "outputs": [],
      "source": [
        "# Test dataset (10 entries)\n",
        "test_dataset = [\n",
        "    {\n",
        "        \"input\": \"mohamed naji dridi\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Mohamed Naji Dridi\", \"Mohammed Nagy Dridi\", \"Muhammad Nagee Dridi\"],\n",
        "            \"Cyrillic\": [\"Мохамед Нажи Дриди\", \"Мохаммед Наги Дриди\", \"Мухаммад Нагий Дриди\"],\n",
        "            \"Arabic\": [\"محمد ناجي دريدي\", \"محمّد ناجي دريدي\", \"محمد ناجى دريدى\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Fatima\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Fatima\", \"Faatimah\", \"Fatma\"],\n",
        "            \"Cyrillic\": [\"Фатима\", \"Фатимах\", \"Фатма\"],\n",
        "            \"Arabic\": [\"فاطمة\", \"فاطمه\", \"فاطما\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Aleksandr Ivanov\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Alexander Ivanov\", \"Alekzandr Ivanow\", \"Alexandr Ivanow\"],\n",
        "            \"Cyrillic\": [\"Александр Иванов\", \"Александар Иваноф\", \"Аляксандр Іванов\"],\n",
        "            \"Arabic\": [\"ألكسندر إيفانوف\", \"أليكسندر إيفانوف\", \"أليكسندار إيفانوف\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"عمر بن الخطاب\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Omar ibn al-Khattab\", \"Umar bin al-Khattab\", \"Omer ben al-Khatab\"],\n",
        "            \"Cyrillic\": [\"Омар ибн аль-Хаттаб\", \"Умар бин аль-Хаттаб\", \"Омер бен аль-Хатаб\"],\n",
        "            \"Arabic\": [\"عمر بن الخطاب\", \"عمر بن الخطّاب\", \"عُمر بن الخطاب\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Sofia Petrova\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Sofia Petrova\", \"Sophia Petrova\", \"Sofiya Petrovna\"],\n",
        "            \"Cyrillic\": [\"София Петрова\", \"Софья Петрова\", \"Сафія Пятрова\"],\n",
        "            \"Arabic\": [\"صوفيا بيتروفا\", \"صوفية بيتروفا\", \"سفيا بيتروفا\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"حسن علي\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Hassan Ali\", \"Hasan Aly\", \"Hussain Ali\"],\n",
        "            \"Cyrillic\": [\"Хассан Али\", \"Хасан Алы\", \"Хусейн Али\"],\n",
        "            \"Arabic\": [\"حسن علي\", \"حسّن علي\", \"حسن عليّ\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Maria Gonzalez\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Maria Gonzalez\", \"Mariya Gonzales\", \"Marie Gonzalvez\"],\n",
        "            \"Cyrillic\": [\"Мария Гонсалес\", \"Мария Гонсалез\", \"Мари Гонсалвес\"],\n",
        "            \"Arabic\": [\"ماريا غونزاليس\", \"مريا غونزاليز\", \"ماري غونزالفيس\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"خالد محمود\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Khaled Mahmoud\", \"Khalid Mahmud\", \"Khalid Mahmod\"],\n",
        "            \"Cyrillic\": [\"Халед Махмуд\", \"Халид Махмуд\", \"Халед Махмод\"],\n",
        "            \"Arabic\": [\"خالد محمود\", \"خالد محمّود\", \"خالد مَحمود\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Said\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Said\", \"Sayed\", \"Sayid\"],\n",
        "            \"Cyrillic\": [\"Саид\", \"Сайед\", \"Сайид\"],\n",
        "            \"Arabic\": [\"سعيد\", \"سيد\", \"سعيّد\"]\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Anna Kowalski\",\n",
        "        \"ground_truth\": {\n",
        "            \"Latin\": [\"Anna Kowalski\", \"Anya Kowalsky\", \"Hanna Kowalska\"],\n",
        "            \"Cyrillic\": [\"Анна Ковальски\", \"Аня Ковальский\", \"Ханна Ковальска\"],\n",
        "            \"Arabic\": [\"آنا كوالسكي\", \"أنيا كوالسكي\", \"هنا كوالسكا\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Save dataset\n",
        "with open(\"test_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(test_dataset, f, ensure_ascii=False, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfFb4B3p6GCV",
        "outputId": "56f25cac-f0f9-4c15-a14f-7c5ee805bec6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: mohamed naji dridi, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: mohamed naji dridi\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Mohamed Naji Dridi\", \"Mohamed Nagy Drije\", \"Muhammad Naji Drije\"],\n",
            "    \"Cyrillic\": [\"Мухаммад Нажи Дриди\", \"Мухаммед Наги Дридь\", \"Мухаммед Нажи Дридий\"],\n",
            "    \"Arabic\": [\"محمد ناجي دريدي\", \"محمد ناجي دريدية\", \"محمد ناجي دريديي\"]\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Fatima, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: Fatima\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima\", \"Fátima\", \"Fatimah\"],\n",
            "    \"Cyrillic\": [\"Фатима\", \"Фатима\", \"Фати́ма\"],\n",
            "    \"Arabic\": [\"فاطمة\", \"فاطمة\", \"فاطمة\"]\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Aleksandr Ivanov, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: Aleksandr Ivanov\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Aleksandr Ivanov\", \"Alexander Ivanoff\", \"Alyaksandr Ivanau\"],\n",
            "    \"Cyrillic\": [\"Александр Иванович\", \"Александар Иванов\", \"Аляксандр Іванаў\"],\n",
            "    \"Arabic\": [\"ألكسندر ايوانوف\", \"أليكسندر ايوانوف\", \"أليكسندار ايوانوف\"]\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: عمر بن الخطاب, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: عمر بن الخطاب\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"'Umar bin Al-Khattab\", \"Umar ibn Al-Khattab\", \"Umar bin Al-Khattabh\"],\n",
            "    \"Cyrillic\": [\"Умар ибн Аль-Хаттаб\", \"Умар ибн Ал-Хаттаб\", \"Умар ибн Ал-Хаттабь\"],\n",
            "    \"Arabic\": [\"عمر بن الخطاب\", \"عمر بن الخطاب\", \"عمر بن الخطاب\"]\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Sofia Petrova, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: Sofia Petrova\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Sofia Petrova\", \"Sophia Petroff\", \"Sofia Petrowa\"],\n",
            "    \"Cyrillic\": [\"София Петрова\", \"Софья Петрова\", \"Софья Петрова\"],\n",
            "    \"Arabic\": [\"سوفيا بيتروف\", \"سوفيه بيتروف\", \"سوفيا بيتروف\"]\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: حسن علي, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: حسن علي\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Husain Ali\", \"Hassan Ali\", \"Hussein Ali\"],\n",
            "    \"Cyrillic\": [\"Хусейн Али\", \"Хасан Али\", \"Хусьян Али\"],\n",
            "    \"Arabic\": [\"حسن علي\", \"حسين علي\", \"حسن علی\"]\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Maria Gonzalez, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: Maria Gonzalez\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "```json\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Maria Gonzalez\", \"Maria Gonzales\", \"Maria Gonzalez-Gonzales\"],\n",
            "    \"Cyrillic\": [\"Мария Гонзалез\", \"Мария Гонзалес\", \"Мария Гонзалез-Гонзалез\"],\n",
            "    \"Arabic\": [\"ماريا كونزاليز\", \"ماريا كونزاليس\", \"ماريا كونزاليز-كونزاليز\"]\n",
            "  }\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: خالد محمود, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: خالد محمود\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Khalid Mohammad\", \"Khaled Mohamed\", \"Khalid Mohamad\"],\n",
            "    \"Cyrillic\": [\"Халид Мухаммад\", \"Халед Мухаммед\", \"Халид Мухаммат\"],\n",
            "    \"Arabic\": [\"خالد محمود\", \"خالد محمود\", \"خالد محمود\"]\n",
            "  }\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Said, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: Said\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "```json\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said\", \"Seid\", \"Saïd\"],\n",
            "    \"Cyrillic\": [\"Саид\", \"Сейд\", \"Сайид\"],\n",
            "    \"Arabic\": [\"سعيد\", \"سيد\", \"سعيد\"]\n",
            "  }\n",
            "}\n",
            "```\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Anna Kowalski, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name.\n",
            "\n",
            "User input name: Anna Kowalski\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Anna Kowalska\", \"Anna Kowalsky\", \"Anna Kowalscy\"],\n",
            "    \"Cyrillic\": [\"Анна Ковальская\", \"Анна Ковальский\", \"Анна Ковальскі\"],\n",
            "    \"Arabic\": [\"أنا كوالسكي\", \"أنا كوالسكيه\", \"أنا كوالسكية\"]\n",
            "  }\n",
            "}\n",
            "Evaluation Results:\n",
            "                Input                                    Generated_Latin  \\\n",
            "0  mohamed naji dridi  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "1              Fatima  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "2    Aleksandr Ivanov  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "3       عمر بن الخطاب  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "4       Sofia Petrova  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "5             حسن علي  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "6      Maria Gonzalez  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "7          خالد محمود  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "8                Said  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "9       Anna Kowalski  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "\n",
            "                                  Generated_Cyrillic  \\\n",
            "0  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "1  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "2  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "3  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "4  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "5  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "6  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "7  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "8  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "9  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "\n",
            "                                    Generated_Arabic  Levenshtein_Latin  \\\n",
            "0  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.830702   \n",
            "1  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.879902   \n",
            "2  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.357843   \n",
            "3  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.890838   \n",
            "4  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.599265   \n",
            "5  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.780637   \n",
            "6  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.920343   \n",
            "7  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.800245   \n",
            "8  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.879902   \n",
            "9  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.860294   \n",
            "\n",
            "   Levenshtein_Cyrillic  Levenshtein_Arabic  BLEU_Latin  BLEU_Cyrillic  \\\n",
            "0              0.879825            0.894444    0.083721       0.073685   \n",
            "1              0.877451            0.979167    0.049870       0.050679   \n",
            "2              0.285539            0.250654    0.595635       0.700605   \n",
            "3              0.872320            0.890079    0.183754       0.176445   \n",
            "4              0.612745            0.511111    0.463192       0.441710   \n",
            "5              0.754902            0.799405    0.253223       0.288903   \n",
            "6              0.959559            0.936111    0.214213       0.268250   \n",
            "7              0.775735            0.799405    0.159378       0.131513   \n",
            "8              0.877451            0.866270    0.059773       0.054280   \n",
            "9              0.877451            0.824603    0.196566       0.250636   \n",
            "\n",
            "   BLEU_Arabic  Semantic_Latin  Semantic_Cyrillic  Semantic_Arabic  \\\n",
            "0     0.137760        0.378927           0.512647         0.707855   \n",
            "1     0.040686        0.282249           0.551767         0.535947   \n",
            "2     0.700178        0.634227           0.856867         0.917534   \n",
            "3     0.225409        0.374283           0.635193         0.633521   \n",
            "4     0.506882        0.555169           0.710784         0.800703   \n",
            "5     0.196030        0.398527           0.707993         0.611580   \n",
            "6     0.201133        0.368564           0.639181         0.705062   \n",
            "7     0.074660        0.403989           0.514682         0.488508   \n",
            "8     0.062341        0.252177           0.625451         0.626778   \n",
            "9     0.107639        0.376550           0.709088         0.751449   \n",
            "\n",
            "   Self_BLEU_Latin  Self_BLEU_Cyrillic  Self_BLEU_Arabic  Format_Correct  \n",
            "0         0.670931            0.767326          0.865619               1  \n",
            "1         0.670931            0.767326          0.865619               1  \n",
            "2         0.670931            0.767326          0.865619               1  \n",
            "3         0.670931            0.767326          0.865619               1  \n",
            "4         0.670931            0.767326          0.865619               1  \n",
            "5         0.670931            0.767326          0.865619               1  \n",
            "6         0.670931            0.767326          0.865619               1  \n",
            "7         0.670931            0.767326          0.865619               1  \n",
            "8         0.670931            0.767326          0.865619               1  \n",
            "9         0.670931            0.767326          0.865619               1  \n",
            "\n",
            "Average Metrics:\n",
            "Avg_Levenshtein_Latin: 0.78\n",
            "Avg_Levenshtein_Cyrillic: 0.78\n",
            "Avg_Levenshtein_Arabic: 0.78\n",
            "Avg_BLEU_Latin: 0.23\n",
            "Avg_BLEU_Cyrillic: 0.24\n",
            "Avg_BLEU_Arabic: 0.23\n",
            "Avg_Semantic_Latin: 0.40\n",
            "Avg_Semantic_Cyrillic: 0.65\n",
            "Avg_Semantic_Arabic: 0.68\n",
            "Avg_Self_BLEU_Latin: 0.67\n",
            "Avg_Self_BLEU_Cyrillic: 0.77\n",
            "Avg_Self_BLEU_Arabic: 0.87\n",
            "Format_Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from Levenshtein import distance\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import itertools\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Initialize metrics\n",
        "st_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "def evaluate_prompt(llm, prompt_template, test_dataset, output_parser):\n",
        "    results = []\n",
        "\n",
        "    for test_case in test_dataset:\n",
        "        input_name = test_case[\"input\"]\n",
        "        ground_truth = test_case[\"ground_truth\"]\n",
        "\n",
        "        # Generate output\n",
        "        formatted_prompt = prompt_template.format(name=input_name)\n",
        "        messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "        raw_output = llm.invoke(messages)\n",
        "        print(f\"Input: {input_name}, Raw output: {raw_output}\")  # Debug\n",
        "\n",
        "        # Parse JSON output\n",
        "        try:\n",
        "            json_start = raw_output.find(\"{\")\n",
        "            json_end = raw_output.rfind(\"}\") + 1\n",
        "            if json_start == -1 or json_end == -1:\n",
        "                raise ValueError(\"No JSON found in output\")\n",
        "            json_str = raw_output[json_start:json_end]\n",
        "            parsed_output = output_parser.parse(json_str)\n",
        "            variations = parsed_output.Orthographic_Variations\n",
        "            latin = variations.Latin\n",
        "            cyrillic = variations.Cyrillic\n",
        "            arabic = variations.Arabic\n",
        "\n",
        "            format_score = 1 if (len(latin) == 3 and len(cyrillic) == 3 and len(arabic) == 3) else 0\n",
        "        except (ValueError, OutputParserException) as e:\n",
        "            print(f\"Parsing error for {input_name}: {e}\")\n",
        "            latin, cyrillic, arabic = [], [], []\n",
        "            format_score = 0\n",
        "\n",
        "        # Tokenize for BLEU/Self-BLEU (character-level)\n",
        "        def tokenize(text):\n",
        "            return list(text)  # Character-level for names\n",
        "\n",
        "        # Levenshtein scores\n",
        "        levenshtein_scores = {\n",
        "            \"Latin\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Latin\"]) for gen in latin] or [1.0],\n",
        "            \"Cyrillic\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Cyrillic\"]) for gen in cyrillic] or [1.0],\n",
        "            \"Arabic\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Arabic\"]) for gen in arabic] or [1.0]\n",
        "        }\n",
        "\n",
        "        # NLTK BLEU scores\n",
        "        bleu_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                gen_tokens = tokenize(g)\n",
        "                gt_tokens_list = [tokenize(gt) for gt in gt_list]\n",
        "                bleu_score = sentence_bleu(\n",
        "                    gt_tokens_list,\n",
        "                    gen_tokens,\n",
        "                    weights=(0.5, 0.5, 0, 0),\n",
        "                    smoothing_function=smoothie\n",
        "                )\n",
        "                bleu_scores[script].append(bleu_score)\n",
        "\n",
        "        # Sentence-transformers semantic similarity\n",
        "        semantic_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                g_emb = st_model.encode(g, convert_to_tensor=True)\n",
        "                gt_embs = [st_model.encode(gt, convert_to_tensor=True) for gt in gt_list]\n",
        "                sem_score = max(float(util.cos_sim(g_emb, gt_emb)) for gt_emb in gt_embs)\n",
        "                semantic_scores[script].append(sem_score)\n",
        "\n",
        "        # Self-BLEU\n",
        "        self_bleu_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen_list, script in [(latin, \"Latin\"), (cyrillic, \"Cyrillic\"), (arabic, \"Arabic\")]:\n",
        "            if len(gen_list) >= 2:\n",
        "                pairs = list(itertools.combinations(gen_list, 2))\n",
        "                for g1, g2 in pairs:\n",
        "                    tokens1, tokens2 = tokenize(g1), tokenize(g2)\n",
        "                    score = sentence_bleu([tokens1], tokens2, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
        "                    self_bleu_scores[script].append(score)\n",
        "            else:\n",
        "                self_bleu_scores[script].append(1.0)  # Penalty for insufficient variations\n",
        "\n",
        "        avg_metrics = {\n",
        "            \"Levenshtein_Latin\": sum(levenshtein_scores[\"Latin\"]) / max(len(levenshtein_scores[\"Latin\"]), 1),\n",
        "            \"Levenshtein_Cyrillic\": sum(levenshtein_scores[\"Cyrillic\"]) / max(len(levenshtein_scores[\"Cyrillic\"]), 1),\n",
        "            \"Levenshtein_Arabic\": sum(levenshtein_scores[\"Arabic\"]) / max(len(levenshtein_scores[\"Arabic\"]), 1),\n",
        "            \"BLEU_Latin\": sum(bleu_scores[\"Latin\"]) / max(len(bleu_scores[\"Latin\"]), 1),\n",
        "            \"BLEU_Cyrillic\": sum(bleu_scores[\"Cyrillic\"]) / max(len(bleu_scores[\"Cyrillic\"]), 1),\n",
        "            \"BLEU_Arabic\": sum(bleu_scores[\"Arabic\"]) / max(len(bleu_scores[\"Arabic\"]), 1),\n",
        "            \"Semantic_Latin\": sum(semantic_scores[\"Latin\"]) / max(len(semantic_scores[\"Latin\"]), 1),\n",
        "            \"Semantic_Cyrillic\": sum(semantic_scores[\"Cyrillic\"]) / max(len(semantic_scores[\"Cyrillic\"]), 1),\n",
        "            \"Semantic_Arabic\": sum(semantic_scores[\"Arabic\"]) / max(len(semantic_scores[\"Arabic\"]), 1),\n",
        "            \"Self_BLEU_Latin\": sum(self_bleu_scores[\"Latin\"]) / max(len(self_bleu_scores[\"Latin\"]), 1) if self_bleu_scores[\"Latin\"] else 1.0,\n",
        "            \"Self_BLEU_Cyrillic\": sum(self_bleu_scores[\"Cyrillic\"]) / max(len(self_bleu_scores[\"Cyrillic\"]), 1) if self_bleu_scores[\"Cyrillic\"] else 1.0,\n",
        "            \"Self_BLEU_Arabic\": sum(self_bleu_scores[\"Arabic\"]) / max(len(self_bleu_scores[\"Arabic\"]), 1) if self_bleu_scores[\"Arabic\"] else 1.0\n",
        "        }\n",
        "\n",
        "        results.append({\n",
        "            \"Input\": input_name,\n",
        "            \"Generated_Latin\": \", \".join(latin),\n",
        "            \"Generated_Cyrillic\": \", \".join(cyrillic),\n",
        "            \"Generated_Arabic\": \", \".join(arabic),\n",
        "            \"Levenshtein_Latin\": avg_metrics[\"Levenshtein_Latin\"],\n",
        "            \"Levenshtein_Cyrillic\": avg_metrics[\"Levenshtein_Cyrillic\"],\n",
        "            \"Levenshtein_Arabic\": avg_metrics[\"Levenshtein_Arabic\"],\n",
        "            \"BLEU_Latin\": avg_metrics[\"BLEU_Latin\"],\n",
        "            \"BLEU_Cyrillic\": avg_metrics[\"BLEU_Cyrillic\"],\n",
        "            \"BLEU_Arabic\": avg_metrics[\"BLEU_Arabic\"],\n",
        "            \"Semantic_Latin\": avg_metrics[\"Semantic_Latin\"],\n",
        "            \"Semantic_Cyrillic\": avg_metrics[\"Semantic_Cyrillic\"],\n",
        "            \"Semantic_Arabic\": avg_metrics[\"Semantic_Arabic\"],\n",
        "            \"Self_BLEU_Latin\": avg_metrics[\"Self_BLEU_Latin\"],\n",
        "            \"Self_BLEU_Cyrillic\": avg_metrics[\"Self_BLEU_Cyrillic\"],\n",
        "            \"Self_BLEU_Arabic\": avg_metrics[\"Self_BLEU_Arabic\"],\n",
        "            \"Format_Correct\": format_score\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    avg_metrics = {\n",
        "        \"Avg_Levenshtein_Latin\": df[\"Levenshtein_Latin\"].mean(),\n",
        "        \"Avg_Levenshtein_Cyrillic\": df[\"Levenshtein_Cyrillic\"].mean(),\n",
        "        \"Avg_Levenshtein_Arabic\": df[\"Levenshtein_Arabic\"].mean(),\n",
        "        \"Avg_BLEU_Latin\": df[\"BLEU_Latin\"].mean(),\n",
        "        \"Avg_BLEU_Cyrillic\": df[\"BLEU_Cyrillic\"].mean(),\n",
        "        \"Avg_BLEU_Arabic\": df[\"BLEU_Arabic\"].mean(),\n",
        "        \"Avg_Semantic_Latin\": df[\"Semantic_Latin\"].mean(),\n",
        "        \"Avg_Semantic_Cyrillic\": df[\"Semantic_Cyrillic\"].mean(),\n",
        "        \"Avg_Semantic_Arabic\": df[\"Semantic_Arabic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Latin\": df[\"Self_BLEU_Latin\"].mean(),\n",
        "        \"Avg_Self_BLEU_Cyrillic\": df[\"Self_BLEU_Cyrillic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Arabic\": df[\"Self_BLEU_Arabic\"].mean(),\n",
        "        \"Format_Accuracy\": df[\"Format_Correct\"].mean()\n",
        "    }\n",
        "\n",
        "    return df, avg_metrics\n",
        "\n",
        "\n",
        "# Run evaluation\n",
        "df_results, avg_metrics = evaluate_prompt(llm, prompt_template, test_dataset, output_parser)\n",
        "df_results.to_csv(\"prompt_evaluation_no_exact_match.csv\", index=False)\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(df_results)\n",
        "print(\"\\nAverage Metrics:\")\n",
        "for k, v in avg_metrics.items():\n",
        "    print(f\"{k}: {v:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYqtCT2-_lAp",
        "outputId": "7c4632d9-682a-4867-ced5-727e6828e176"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: mohamed naji dridi, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name mohamed naji dridi.\n",
            "\n",
            "User input name: mohamed naji dridi\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Mohamed Naji Dridi\", \"Mohamed Nagy Dridi\", \"Mohamed Nagy Dridhi\"],\n",
            "    \"Cyrillic\": [\"Мохамед Нажи Дриди\", \"Мохамед Наги Дриди\", \"Мохамед Наги Дриди\"],\n",
            "    \"Arabic\": [\"محمد ناجي دريدي\", \"محمد ناجي دريدي\", \"محمد ناجي دريدي\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for mohamed naji dridi: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Fatima, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Fatima.\n",
            "\n",
            "User input name: Fatima\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima\", \"Fathima\", \"Fatiima\"],\n",
            "    \"Cyrillic\": [\"Фатима\", \"Фатима\", \"Фатима\"],\n",
            "    \"Arabic\": [\"فاطمة\", \"فاطمة\", \"فاطمة\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for Fatima: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Aleksandr Ivanov, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Aleksandr Ivanov.\n",
            "\n",
            "User input name: Aleksandr Ivanov\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Aleksandr Ivanov\", \"Alexander Ivanoff\", \"Aleksandr Ivanowicz\"],\n",
            "    \"Cyrillic\": [\"Александр Иванович\", \"Александар Иванов\", \"Аляксандр Іванаў\"],\n",
            "    \"Arabic\": [\"اَلْكَسَنْدَر اِيْفَانُوف\", \"الكسندر ايفانوف\", \"الكسندر ايفانوف\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for Aleksandr Ivanov: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: عمر بن الخطاب, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name عمر بن الخطاب.\n",
            "\n",
            "User input name: عمر بن الخطاب\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Omr bin Al-Khattab\", \"Umar bin Al-Khattab\", \"Umar Ibn Al-Khattab\"],\n",
            "    \"Cyrillic\": [\"Омир бен Аль-Хаттаб\", \"Умар бен Аль-Хаттаб\", \"Умар Ібн Аль-Хаттаб\"],\n",
            "    \"Arabic\": [\"عمر بن الخطاب\", \"عمر بن الخطاب\", \"عمر بن الخطاب\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for عمر بن الخطاب: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Sofia Petrova, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Sofia Petrova.\n",
            "\n",
            "User input name: Sofia Petrova\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Sofia Petrova\", \"Sofia Petrovaa\", \"Sofia Petrovaia\"],\n",
            "    \"Cyrillic\": [\"София Петрова\", \"Софья Петрова\", \"София Петроваа\"],\n",
            "    \"Arabic\": [\"سوفيا بيتروفا\", \"سوفيا بيتروفة\", \"سوفيا بيتروفيا\"]\n",
            "  }\n",
            "}\n",
            "```\n",
            "Parsed variations for Sofia Petrova: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: حسن علي, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name حسن علي.\n",
            "\n",
            "User input name: حسن علي\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Husain Ali\", \"Hussain Aly\", \"Husein Ali\"],\n",
            "    \"Cyrillic\": [\"Хусейн Али\", \"Хусайн Али\", \"Хусейнъ Али\"],\n",
            "    \"Arabic\": [\"حسن علي\", \"حسن علي\", \"حسن علي\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for حسن علي: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Maria Gonzalez, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Maria Gonzalez.\n",
            "\n",
            "User input name: Maria Gonzalez\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Maria Gonzales\", \"Maria Gonzalez-Garcia\", \"Maria Gonzalez-Lopez\"],\n",
            "    \"Cyrillic\": [\"Мария Гонсалес\", \"Мария Гонзалез-Гарсия\", \"Мария Гонзалез-Лопес\"],\n",
            "    \"Arabic\": [\"ماريا غونزاليز\", \"ماريا غونزاليز-غارسيا\", \"ماريا غونزاليز-لوبيس\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for Maria Gonzalez: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: خالد محمود, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name خالد محمود.\n",
            "\n",
            "User input name: خالد محمود\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Khaled Mohammed\", \"Khalid Mohammad\", \"Khaleed Mohamad\"],\n",
            "    \"Cyrillic\": [\"Халид Мохаммед\", \"Халед Мухаммад\", \"Халед Мохаммед\"],\n",
            "    \"Arabic\": [\"خالد محمود\", \"خالد محمود\", \"خالد محمود\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for خالد محمود: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Said, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Said.\n",
            "\n",
            "User input name: Said\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said\", \"Seid\", \"Saeed\"],\n",
            "    \"Cyrillic\": [\"Саид\", \"Сейд\", \"Саид\"],\n",
            "    \"Arabic\": [\"سعيد\", \"سيد\", \"سعيد\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for Said: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Anna Kowalski, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Anna Kowalski.\n",
            "\n",
            "User input name: Anna Kowalski\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Anna Kowalska\", \"Anna Kowalski\", \"Anna Kowalskiewicz\"],\n",
            "    \"Cyrillic\": [\"Анна Ковальская\", \"Анна Ковальский\", \"Анна Ковальскiй\"],\n",
            "    \"Arabic\": [\"أنا كوالسكي\", \"أنا كوالسكية\", \"أنا كوالسكيا\"]\n",
            "  }\n",
            "}\n",
            "Parsed variations for Anna Kowalski: Latin=['Alexander Petrov', 'Alekzandr Petroff', 'Alyaksandr Petrou'], Cyrillic=['Александр Петров', 'Александар Пятров', 'Аляксандр Пятроў'], Arabic=['ألكسندر بيتروف', 'أليكسندر بيتروف', 'أليكسندار بيتروف']\n",
            "Evaluation Results:\n",
            "                Input                                    Generated_Latin  \\\n",
            "0  mohamed naji dridi  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "1              Fatima  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "2    Aleksandr Ivanov  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "3       عمر بن الخطاب  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "4       Sofia Petrova  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "5             حسن علي  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "6      Maria Gonzalez  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "7          خالد محمود  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "8                Said  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "9       Anna Kowalski  Alexander Petrov, Alekzandr Petroff, Alyaksand...   \n",
            "\n",
            "                                  Generated_Cyrillic  \\\n",
            "0  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "1  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "2  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "3  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "4  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "5  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "6  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "7  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "8  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "9  Александр Петров, Александар Пятров, Аляксандр...   \n",
            "\n",
            "                                    Generated_Arabic  Levenshtein_Latin  \\\n",
            "0  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.830702   \n",
            "1  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.879902   \n",
            "2  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.357843   \n",
            "3  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.890838   \n",
            "4  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.599265   \n",
            "5  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.780637   \n",
            "6  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.920343   \n",
            "7  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.800245   \n",
            "8  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.879902   \n",
            "9  ألكسندر بيتروف, أليكسندر بيتروف, أليكسندار بيتروف           0.860294   \n",
            "\n",
            "   Levenshtein_Cyrillic  Levenshtein_Arabic  BLEU_Latin  BLEU_Cyrillic  \\\n",
            "0              0.879825            0.894444    0.083721       0.073685   \n",
            "1              0.877451            0.979167    0.049870       0.050679   \n",
            "2              0.285539            0.250654    0.595635       0.700605   \n",
            "3              0.872320            0.890079    0.183754       0.176445   \n",
            "4              0.612745            0.511111    0.463192       0.441710   \n",
            "5              0.754902            0.799405    0.253223       0.288903   \n",
            "6              0.959559            0.936111    0.214213       0.268250   \n",
            "7              0.775735            0.799405    0.159378       0.131513   \n",
            "8              0.877451            0.866270    0.059773       0.054280   \n",
            "9              0.877451            0.824603    0.196566       0.250636   \n",
            "\n",
            "   BLEU_Arabic  Semantic_Latin  Semantic_Cyrillic  Semantic_Arabic  \\\n",
            "0     0.137760        0.503175           0.538926         0.488030   \n",
            "1     0.040686        0.528449           0.527431         0.578116   \n",
            "2     0.700178        0.698280           0.873317         0.848040   \n",
            "3     0.225409        0.430224           0.443905         0.541162   \n",
            "4     0.506882        0.627273           0.726320         0.713550   \n",
            "5     0.196030        0.500564           0.566010         0.487822   \n",
            "6     0.201133        0.360126           0.467523         0.478583   \n",
            "7     0.074660        0.484032           0.575292         0.562942   \n",
            "8     0.062341        0.361116           0.568204         0.515676   \n",
            "9     0.107639        0.344642           0.612730         0.531441   \n",
            "\n",
            "   Self_BLEU_Latin  Self_BLEU_Cyrillic  Self_BLEU_Arabic  Format_Correct  \n",
            "0         0.670931            0.767326          0.865619               1  \n",
            "1         0.670931            0.767326          0.865619               1  \n",
            "2         0.670931            0.767326          0.865619               1  \n",
            "3         0.670931            0.767326          0.865619               1  \n",
            "4         0.670931            0.767326          0.865619               1  \n",
            "5         0.670931            0.767326          0.865619               1  \n",
            "6         0.670931            0.767326          0.865619               1  \n",
            "7         0.670931            0.767326          0.865619               1  \n",
            "8         0.670931            0.767326          0.865619               1  \n",
            "9         0.670931            0.767326          0.865619               1  \n",
            "\n",
            "Average Metrics:\n",
            "Avg_Levenshtein_Latin: 0.78\n",
            "Avg_Levenshtein_Cyrillic: 0.78\n",
            "Avg_Levenshtein_Arabic: 0.78\n",
            "Avg_BLEU_Latin: 0.23\n",
            "Avg_BLEU_Cyrillic: 0.24\n",
            "Avg_BLEU_Arabic: 0.23\n",
            "Avg_Semantic_Latin: 0.48\n",
            "Avg_Semantic_Cyrillic: 0.59\n",
            "Avg_Semantic_Arabic: 0.57\n",
            "Avg_Self_BLEU_Latin: 0.67\n",
            "Avg_Self_BLEU_Cyrillic: 0.77\n",
            "Avg_Self_BLEU_Arabic: 0.87\n",
            "Format_Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from Levenshtein import distance\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import itertools\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Initialize metrics\n",
        "st_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "def evaluate_prompt(llm, prompt_template, test_dataset, output_parser):\n",
        "    results = []\n",
        "\n",
        "    for test_case in test_dataset:\n",
        "        input_name = test_case[\"input\"]\n",
        "        ground_truth = test_case[\"ground_truth\"]\n",
        "\n",
        "        # Generate output\n",
        "        formatted_prompt = prompt_template.format(name=input_name)\n",
        "        messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "        raw_output = llm.invoke(messages)\n",
        "        print(f\"Input: {input_name}, Raw output: {raw_output}\")  # Debug\n",
        "\n",
        "        # Parse JSON output\n",
        "        try:\n",
        "            json_start = raw_output.find(\"{\")\n",
        "            json_end = raw_output.rfind(\"}\") + 1\n",
        "            if json_start == -1 or json_end == -1:\n",
        "                raise ValueError(\"No JSON found in output\")\n",
        "            json_str = raw_output[json_start:json_end]\n",
        "            parsed_output = output_parser.parse(json_str)\n",
        "            variations = parsed_output.Orthographic_Variations\n",
        "            latin = variations.Latin\n",
        "            cyrillic = variations.Cyrillic\n",
        "            arabic = variations.Arabic\n",
        "            print(f\"Parsed variations for {input_name}: Latin={latin}, Cyrillic={cyrillic}, Arabic={arabic}\")  # Debug\n",
        "\n",
        "            format_score = 1 if (len(latin) == 3 and len(cyrillic) == 3 and len(arabic) == 3) else 0\n",
        "        except (ValueError, OutputParserException) as e:\n",
        "            print(f\"Parsing error for {input_name}: {e}\")\n",
        "            latin, cyrillic, arabic = [], [], []\n",
        "            format_score = 0\n",
        "\n",
        "        # Tokenize for BLEU/Self-BLEU (character-level)\n",
        "        def tokenize(text):\n",
        "            return list(text)  # Character-level for names\n",
        "\n",
        "        # Levenshtein scores\n",
        "        levenshtein_scores = {\n",
        "            \"Latin\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Latin\"]) for gen in latin] or [1.0],\n",
        "            \"Cyrillic\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Cyrillic\"]) for gen in cyrillic] or [1.0],\n",
        "            \"Arabic\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Arabic\"]) for gen in arabic] or [1.0]\n",
        "        }\n",
        "\n",
        "        # NLTK BLEU scores\n",
        "        bleu_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                gen_tokens = tokenize(g)\n",
        "                gt_tokens_list = [tokenize(gt) for gt in gt_list]\n",
        "                bleu_score = sentence_bleu(\n",
        "                    gt_tokens_list,\n",
        "                    gen_tokens,\n",
        "                    weights=(0.5, 0.5, 0, 0),\n",
        "                    smoothing_function=smoothie\n",
        "                )\n",
        "                bleu_scores[script].append(bleu_score)\n",
        "\n",
        "        # Sentence-transformers semantic similarity\n",
        "        semantic_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                g_emb = st_model.encode(g, convert_to_tensor=True)\n",
        "                gt_embs = [st_model.encode(gt, convert_to_tensor=True) for gt in gt_list]\n",
        "                sem_score = max(float(util.cos_sim(g_emb, gt_emb)) for gt_emb in gt_embs)\n",
        "                semantic_scores[script].append(sem_score)\n",
        "\n",
        "        # Self-BLEU\n",
        "        self_bleu_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen_list, script in [(latin, \"Latin\"), (cyrillic, \"Cyrillic\"), (arabic, \"Arabic\")]:\n",
        "            if len(gen_list) >= 2:\n",
        "                pairs = list(itertools.combinations(gen_list, 2))\n",
        "                for g1, g2 in pairs:\n",
        "                    tokens1, tokens2 = tokenize(g1), tokenize(g2)\n",
        "                    score = sentence_bleu([tokens1], tokens2, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
        "                    self_bleu_scores[script].append(score)\n",
        "            else:\n",
        "                self_bleu_scores[script].append(1.0)  # Penalty for insufficient variations\n",
        "\n",
        "        avg_metrics = {\n",
        "            \"Levenshtein_Latin\": sum(levenshtein_scores[\"Latin\"]) / max(len(levenshtein_scores[\"Latin\"]), 1),\n",
        "            \"Levenshtein_Cyrillic\": sum(levenshtein_scores[\"Cyrillic\"]) / max(len(levenshtein_scores[\"Cyrillic\"]), 1),\n",
        "            \"Levenshtein_Arabic\": sum(levenshtein_scores[\"Arabic\"]) / max(len(levenshtein_scores[\"Arabic\"]), 1),\n",
        "            \"BLEU_Latin\": sum(bleu_scores[\"Latin\"]) / max(len(bleu_scores[\"Latin\"]), 1),\n",
        "            \"BLEU_Cyrillic\": sum(bleu_scores[\"Cyrillic\"]) / max(len(bleu_scores[\"Cyrillic\"]), 1),\n",
        "            \"BLEU_Arabic\": sum(bleu_scores[\"Arabic\"]) / max(len(bleu_scores[\"Arabic\"]), 1),\n",
        "            \"Semantic_Latin\": sum(semantic_scores[\"Latin\"]) / max(len(semantic_scores[\"Latin\"]), 1),\n",
        "            \"Semantic_Cyrillic\": sum(semantic_scores[\"Cyrillic\"]) / max(len(semantic_scores[\"Cyrillic\"]), 1),\n",
        "            \"Semantic_Arabic\": sum(semantic_scores[\"Arabic\"]) / max(len(semantic_scores[\"Arabic\"]), 1),\n",
        "            \"Self_BLEU_Latin\": sum(self_bleu_scores[\"Latin\"]) / max(len(self_bleu_scores[\"Latin\"]), 1) if self_bleu_scores[\"Latin\"] else 1.0,\n",
        "            \"Self_BLEU_Cyrillic\": sum(self_bleu_scores[\"Cyrillic\"]) / max(len(self_bleu_scores[\"Cyrillic\"]), 1) if self_bleu_scores[\"Cyrillic\"] else 1.0,\n",
        "            \"Self_BLEU_Arabic\": sum(self_bleu_scores[\"Arabic\"]) / max(len(self_bleu_scores[\"Arabic\"]), 1) if self_bleu_scores[\"Arabic\"] else 1.0\n",
        "        }\n",
        "\n",
        "        results.append({\n",
        "            \"Input\": input_name,\n",
        "            \"Generated_Latin\": \", \".join(latin),\n",
        "            \"Generated_Cyrillic\": \", \".join(cyrillic),\n",
        "            \"Generated_Arabic\": \", \".join(arabic),\n",
        "            \"Levenshtein_Latin\": avg_metrics[\"Levenshtein_Latin\"],\n",
        "            \"Levenshtein_Cyrillic\": avg_metrics[\"Levenshtein_Cyrillic\"],\n",
        "            \"Levenshtein_Arabic\": avg_metrics[\"Levenshtein_Arabic\"],\n",
        "            \"BLEU_Latin\": avg_metrics[\"BLEU_Latin\"],\n",
        "            \"BLEU_Cyrillic\": avg_metrics[\"BLEU_Cyrillic\"],\n",
        "            \"BLEU_Arabic\": avg_metrics[\"BLEU_Arabic\"],\n",
        "            \"Semantic_Latin\": avg_metrics[\"Semantic_Latin\"],\n",
        "            \"Semantic_Cyrillic\": avg_metrics[\"Semantic_Cyrillic\"],\n",
        "            \"Semantic_Arabic\": avg_metrics[\"Semantic_Arabic\"],\n",
        "            \"Self_BLEU_Latin\": avg_metrics[\"Self_BLEU_Latin\"],\n",
        "            \"Self_BLEU_Cyrillic\": avg_metrics[\"Self_BLEU_Cyrillic\"],\n",
        "            \"Self_BLEU_Arabic\": avg_metrics[\"Self_BLEU_Arabic\"],\n",
        "            \"Format_Correct\": format_score\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    avg_metrics = {\n",
        "        \"Avg_Levenshtein_Latin\": df[\"Levenshtein_Latin\"].mean(),\n",
        "        \"Avg_Levenshtein_Cyrillic\": df[\"Levenshtein_Cyrillic\"].mean(),\n",
        "        \"Avg_Levenshtein_Arabic\": df[\"Levenshtein_Arabic\"].mean(),\n",
        "        \"Avg_BLEU_Latin\": df[\"BLEU_Latin\"].mean(),\n",
        "        \"Avg_BLEU_Cyrillic\": df[\"BLEU_Cyrillic\"].mean(),\n",
        "        \"Avg_BLEU_Arabic\": df[\"BLEU_Arabic\"].mean(),\n",
        "        \"Avg_Semantic_Latin\": df[\"Semantic_Latin\"].mean(),\n",
        "        \"Avg_Semantic_Cyrillic\": df[\"Semantic_Cyrillic\"].mean(),\n",
        "        \"Avg_Semantic_Arabic\": df[\"Semantic_Arabic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Latin\": df[\"Self_BLEU_Latin\"].mean(),\n",
        "        \"Avg_Self_BLEU_Cyrillic\": df[\"Self_BLEU_Cyrillic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Arabic\": df[\"Self_BLEU_Arabic\"].mean(),\n",
        "        \"Format_Accuracy\": df[\"Format_Correct\"].mean()\n",
        "    }\n",
        "\n",
        "    return df, avg_metrics\n",
        "\n",
        "# Install dependencies\n",
        "!pip install python-Levenshtein pandas nltk sentence-transformers --quiet\n",
        "\n",
        "# Run evaluation\n",
        "df_results, avg_metrics = evaluate_prompt(llm, prompt_template, test_dataset, output_parser)\n",
        "df_results.to_csv(\"prompt_evaluation_no_exact_match.csv\", index=False)\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(df_results)\n",
        "print(\"\\nAverage Metrics:\")\n",
        "for k, v in avg_metrics.items():\n",
        "    print(f\"{k}: {v:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVL80K4rI3FG"
      },
      "source": [
        "#last demi-eval version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bpD-8avMz-8",
        "outputId": "f5751d2f-0a6c-4c3f-bdb9-28caa53a7dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fuzzywuzzy\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting fuzzy\n",
            "  Downloading Fuzzy-1.2.2.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.8-py3-none-any.whl.metadata (13 kB)\n",
            "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading Unidecode-1.3.8-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fuzzy\n",
            "  Building wheel for fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fuzzy: filename=Fuzzy-1.2.2-cp311-cp311-linux_x86_64.whl size=220712 sha256=b87ef7c300eb3402c336579f5b6ad76bd783ca96ac3f13f665e3ff35a09f4a72\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/1c/77/28af87176ebf6eb6208c17e64a45a8e48eda4194bd8f605096\n",
            "Successfully built fuzzy\n",
            "Installing collected packages: fuzzywuzzy, fuzzy, unidecode\n",
            "Successfully installed fuzzy-1.2.2 fuzzywuzzy-0.18.0 unidecode-1.3.8\n"
          ]
        }
      ],
      "source": [
        "!pip install fuzzywuzzy fuzzy unidecode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fd12a90980564b51a34031cff92a2670",
            "ceb73a524744493887975fffac67d371",
            "0237e16efcf741219f81ee989b0a9040",
            "d01dbd62996446a487f21e13391cb5ae",
            "28283d3e170c4e1ab3728340010aab9e",
            "cf865dcb4f1a4bc39131fb0986839a5b",
            "bd2f630d7e52435ab1af8a218567e196",
            "97d8da83f4184d33a6a0289d22339804",
            "c9d542e8186447c89723dc9bcb34d154",
            "c06f8ff147d24c5996d0f84693e1a57e",
            "6e640ebe5def47aab04c97efdcf5bd82",
            "ab7259bf9362486ba045daf398529923",
            "23d871e7f6834e2d99c3adde8aa758fa",
            "a5b008bfd06b45ffa6e9f3b0d0170ad3",
            "29ccacc99f5d4f188af29a347b5de5a0",
            "3dc674970a9c4deeb58277ecd2eb8b3b",
            "7e547fd392c34381a7389ad26290df26",
            "9edd682921b949ab9c27b07dd4df9380",
            "39d2cdcd224148e4ba7d4acc2ab34b79",
            "d1c7a527c05f4621a3c4b439f7367d9b",
            "2d5c93c4193644479afc4a2a24e677ab",
            "ec43d09ef2824f52a024e47c406e07e2",
            "2ace33074d7749358d4fb77250f88473",
            "39730271e29a44af8cfd588695411b93",
            "024a9940b4304d63825c83207b67a443",
            "966de2e698da42bb9a4d874de245f456",
            "f19740b4d4164057a94b04b7da904dd0",
            "5ce170ada6be4bb1a840c979310bf49d",
            "1458acfa568849f9bc49d3da8399d772",
            "44a647cfa23a4c13b45756a56d0f295c",
            "05df1076ca4f464f8a33adbf8657cc42",
            "4e5addddea1e4d8dac37fab0cb17a0c0",
            "fd04cca4cdb84fd899996acf8036e7ec",
            "48a456ef3f754dc1ac7f1b356333e9bf",
            "6dfb61fc173246b8acf683357fc0d471",
            "b01ea239ccdb4cbcabccc4a5a7ea2678",
            "34b99b98fc9d43f68c9e581dc749b904",
            "41936a6b595d4c13849adb1405b3a462",
            "127976d896124873bc59add1c1d82cc8",
            "b41169c8d0ea48c5b777ff3d22b18ac2",
            "94c857429fe34f689d6934c698491483",
            "74806dcd6ffe4f1fa01588d5dec4fa2a",
            "bf2914667f1f418785c7a39a2bc45c2c",
            "3321b9fdae1b44a4a259a53a2e304c30",
            "9369a4c958d04a05a853adca0f9de602",
            "40823c33d69e44b39f20274cd80645cc",
            "70e73028847244a2b373a377f2b15c88",
            "13c00ef8f4374159beb32b1910abec5e",
            "7cfdff1d8b5d4909b5c2b3c16926a6ed",
            "ee8ddebdc2454abf81aabd3354e59ac6",
            "0193b4845adc4d1b8d1c354d48133ea9",
            "a3c7398e37e34afb879283b16ee72a10",
            "9df6aab751184fb3926eff8df986e5bd",
            "ec8131b6072c4df689355d820a75ad0f",
            "a84366e1ca904c438e073856a40aa535",
            "c7846981434c4a09abfa0a32e5e80b41",
            "65e10db4a877402bbe40eae501409ad9",
            "d00062d522c94aa5ba8d1c89ed1b11d6",
            "d1c50eeb6e7d4d40835987117726e320",
            "2661ecd3e01246e38cf1d36afe7592c9",
            "fa9451d63a89467b8e9649cfc703cec5",
            "f8cb00e034a940419092febf6c188050",
            "a29e426eef0d46b9996f19474a4c726c",
            "aae9eaf97e514a54b83a47dbffde00cc",
            "5ab602ce8b364095886406611860507e",
            "b8dd49fb468e44cd81b4f4be55011105",
            "88486219b70440e88e2760a76c883824",
            "f565876eda0c49eaafffba3e59a06d8a",
            "01105842233748d28ecf8dea4cc5966e",
            "fb7fce2f01564960b764c9baded98fad",
            "367798755ac646e7a18b722625cef24c",
            "aed8bf2653104b718463ca22e8bdfbd1",
            "496f4339992144bb820fb043f67f9e82",
            "c7bad08ee2fb4cc4b3ccb080659e5d08",
            "5c7f0bffd18345b688273055b9c62840",
            "ea2cd8b473ce4d87b159d8b358da7c99",
            "298b4d110a154b73b7729e14719ef7f3",
            "346448d200e44dd59d3decced75ca77f",
            "18389511a94b48d4a8f43be0109fab7c",
            "fc36e0d966c44fd7ac9087bc036643f5",
            "cfc3522591754ac883de381acd7242dd",
            "cb406393f0174cffa7af28a5a168dc8d",
            "84463490da9740fbb53508726af5c908",
            "f4fabc3a1825476790bec1e4bafcd99c",
            "a0a11cc762c44ab4b2c780902e70f5e0",
            "895bf3119d27467283e2499f2fc88cd3",
            "c37da8ce8afb437eab4ff5e720f909f5",
            "16a2112b60c64afd8004ada55efb45a7",
            "998cb884774140a1807e585ee58c6919",
            "578806760d0447919bc044189de16424",
            "d78732bf43944172a2d73fbbeb1a4531",
            "e397951b8d764aa18c60db531583e673",
            "3d19a883a5ca4c4d89892cf7ea66c7db",
            "45cef6821ebf400f9c7e6e54a609a4f7",
            "77af2770a99b48158764132327fa7452",
            "22d228f107b2466b938c1e03d40581b3",
            "79ef11e1cd4943c9b969fafbe1c78b9c",
            "bd25ec2451f44e6f941c567ab0e067e1",
            "992fa0358c9c45f4b7dd46d0b9a86994",
            "d8a750c774c343b6ab1185e33805e30b",
            "85d5e9287d854aed94e4cf454087e978",
            "a11030b9a07e434cbdff64646f09fecc",
            "fdfde3afdfb743bcab41242f88b478e7",
            "bd56c8d5a3eb425c8887d80f089c4334",
            "3dd255845549427bb27e0edcd4a52f06",
            "49924cedb298482aa0ecf4c5aed429cf",
            "07c9ac8ef90a4ca1b9ae599b8b9f8aa4",
            "627a747bf8a545758badc10575af64a6",
            "73d28ccd0989405e98e32b56f1750eb9",
            "3fa423787ffa4502a91970e6edde6492"
          ]
        },
        "id": "2z8GVHtII1nA",
        "outputId": "93394de7-5c5f-4d06-8c66-2373b7844831"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd12a90980564b51a34031cff92a2670"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab7259bf9362486ba045daf398529923"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/3.89k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ace33074d7749358d4fb77250f88473"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48a456ef3f754dc1ac7f1b356333e9bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9369a4c958d04a05a853adca0f9de602"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7846981434c4a09abfa0a32e5e80b41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88486219b70440e88e2760a76c883824"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "346448d200e44dd59d3decced75ca77f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "998cb884774140a1807e585ee58c6919"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d8a750c774c343b6ab1185e33805e30b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: mohamed naji dridi, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name mohamed naji dridi.\n",
            "\n",
            "User input name: mohamed naji dridi\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Mohamed Naji Dridi\", \"Mohamed N'Ji Dridi\", \"Mohamed Nagy Dridi\"],\n",
            "    \"Cyrillic\": [\"Мохамед Нажи Дриди\", \"Мохаммед Нажі Дриді\", \"Мохамед Наги Дриди\"],\n",
            "    \"Arabic\": [\"محمد ناجي دريدي\", \"محمد نجي دريدي\", \"محمد ناجي دريدي\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Mohamed Naji Dridi\", \"Mohamed N'Ji Dridi\", \"Mohamed Nagy Dridi\"],\n",
            "    \"Cyrillic\": [\"Мохамед Нажи Дриди\", \"Мохаммед Нажі Дриді\", \"Мохамед Наги Дриди\"],\n",
            "    \"Arabic\": [\"محمد ناجي دريدي\", \"محمد نجي دريدي\", \"محمد ناجي دريدي\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Mohamed Naji Dridi', \"Mohamed N'Ji Dridi\", 'Mohamed Nagy Dridi'], 'Cyrillic': ['Мохамед Нажи Дриди', 'Мохаммед Нажі Дриді', 'Мохамед Наги Дриди'], 'Arabic': ['محمد ناجي دريدي', 'محمد نجي دريدي', 'محمد ناجي دريدي']}}\n",
            "Parsed variations for mohamed naji dridi: Latin=['Mohamed Naji Dridi', \"Mohamed N'Ji Dridi\", 'Mohamed Nagy Dridi'], Cyrillic=['Мохамед Нажи Дриди', 'Мохаммед Нажі Дриді', 'Мохамед Наги Дриди'], Arabic=['محمد ناجي دريدي', 'محمد نجي دريدي', 'محمد ناجي دريدي']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Fatima, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Fatima.\n",
            "\n",
            "User input name: Fatima\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima\", \"Fátima\", \"Fatima\"],\n",
            "    \"Cyrillic\": [\"Фатима\", \"Фатьяма\", \"Фатимаха\"],\n",
            "    \"Arabic\": [\"فاطمة\", \"فاطمه\", \"فاطما\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima\", \"Fátima\", \"Fatima\"],\n",
            "    \"Cyrillic\": [\"Фатима\", \"Фатьяма\", \"Фатимаха\"],\n",
            "    \"Arabic\": [\"فاطمة\", \"فاطمه\", \"فاطما\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Fatima', 'Fátima', 'Fatima'], 'Cyrillic': ['Фатима', 'Фатьяма', 'Фатимаха'], 'Arabic': ['فاطمة', 'فاطمه', 'فاطما']}}\n",
            "Parsed variations for Fatima: Latin=['Fatima', 'Fátima', 'Fatima'], Cyrillic=['Фатима', 'Фатьяма', 'Фатимаха'], Arabic=['فاطمة', 'فاطمه', 'فاطما']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Aleksandr Ivanov, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Aleksandr Ivanov.\n",
            "\n",
            "User input name: Aleksandr Ivanov\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "```json\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Aleksandr Ivanov\", \"Alexander Ivanoff\", \"Alekander Ivanovich\"],\n",
            "    \"Cyrillic\": [\"Александр Иванович\", \"Александар Иванов\", \"Алєксандр Іваноў\"],\n",
            "    \"Arabic\": [\"اَليكسانْدر إيْفَانْوْف\", \"اليكسندر إيفانوف\", \"اليكسندر إيفانوف\"]\n",
            "  }\n",
            "}\n",
            "```\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Aleksandr Ivanov\", \"Alexander Ivanoff\", \"Alekander Ivanovich\"],\n",
            "    \"Cyrillic\": [\"Александр Иванович\", \"Александар Иванов\", \"Алєксандр Іваноў\"],\n",
            "    \"Arabic\": [\"اَليكسانْدر إيْفَانْوْف\", \"اليكسندر إيفانوف\", \"اليكسندر إيفانوف\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Aleksandr Ivanov', 'Alexander Ivanoff', 'Alekander Ivanovich'], 'Cyrillic': ['Александр Иванович', 'Александар Иванов', 'Алєксандр Іваноў'], 'Arabic': ['اَليكسانْدر إيْفَانْوْف', 'اليكسندر إيفانوف', 'اليكسندر إيفانوف']}}\n",
            "Parsed variations for Aleksandr Ivanov: Latin=['Aleksandr Ivanov', 'Alexander Ivanoff', 'Alekander Ivanovich'], Cyrillic=['Александр Иванович', 'Александар Иванов', 'Алєксандр Іваноў'], Arabic=['اَليكسانْدر إيْفَانْوْف', 'اليكسندر إيفانوف', 'اليكسندر إيفانوف']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: عمر بن الخطاب, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name عمر بن الخطاب.\n",
            "\n",
            "User input name: عمر بن الخطاب\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Omr bin Al-Khattab\", \"Umar Ibn Al-Khattab\", \"Umar ibn Al-Khattab\"],\n",
            "    \"Cyrillic\": [\"Омар Ибн Аль-Хаттаб\", \"Умар Ибн Аль-Хаттаб\", \"Умар ибн Аль-Хаттаб\"],\n",
            "    \"Arabic\": [\"عمر بن الخطاب\", \"عمر بن الخطاب\", \"عمر بن الخطاب\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Omr bin Al-Khattab\", \"Umar Ibn Al-Khattab\", \"Umar ibn Al-Khattab\"],\n",
            "    \"Cyrillic\": [\"Омар Ибн Аль-Хаттаб\", \"Умар Ибн Аль-Хаттаб\", \"Умар ибн Аль-Хаттаб\"],\n",
            "    \"Arabic\": [\"عمر بن الخطاب\", \"عمر بن الخطاب\", \"عمر بن الخطاب\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Omr bin Al-Khattab', 'Umar Ibn Al-Khattab', 'Umar ibn Al-Khattab'], 'Cyrillic': ['Омар Ибн Аль-Хаттаб', 'Умар Ибн Аль-Хаттаб', 'Умар ибн Аль-Хаттаб'], 'Arabic': ['عمر بن الخطاب', 'عمر بن الخطاب', 'عمر بن الخطاب']}}\n",
            "Parsed variations for عمر بن الخطاب: Latin=['Omr bin Al-Khattab', 'Umar Ibn Al-Khattab', 'Umar ibn Al-Khattab'], Cyrillic=['Омар Ибн Аль-Хаттаб', 'Умар Ибн Аль-Хаттаб', 'Умар ибн Аль-Хаттаб'], Arabic=['عمر بن الخطاب', 'عمر بن الخطاب', 'عمر بن الخطاب']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Sofia Petrova, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Sofia Petrova.\n",
            "\n",
            "User input name: Sofia Petrova\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Sofia Petrova\", \"Sophia Petrov\", \"Sofia Petrova (Americanized)\"],\n",
            "    \"Cyrillic\": [\"София Петрова\", \"Софья Петрова\", \"София Петрова (Дореволюционная транскрипция)\"],\n",
            "    \"Arabic\": [\"سوفيا بيتروفا\", \"سوفيه بيتروفا\", \"سوفيا بيتروفا (ترجمة معنوية)\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Sofia Petrova\", \"Sophia Petrov\", \"Sofia Petrova (Americanized)\"],\n",
            "    \"Cyrillic\": [\"София Петрова\", \"Софья Петрова\", \"София Петрова (Дореволюционная транскрипция)\"],\n",
            "    \"Arabic\": [\"سوفيا بيتروفا\", \"سوفيه بيتروفا\", \"سوفيا بيتروفا (ترجمة معنوية)\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Sofia Petrova', 'Sophia Petrov', 'Sofia Petrova (Americanized)'], 'Cyrillic': ['София Петрова', 'Софья Петрова', 'София Петрова (Дореволюционная транскрипция)'], 'Arabic': ['سوفيا بيتروفا', 'سوفيه بيتروفا', 'سوفيا بيتروفا (ترجمة معنوية)']}}\n",
            "Parsed variations for Sofia Petrova: Latin=['Sofia Petrova', 'Sophia Petrov', 'Sofia Petrova (Americanized)'], Cyrillic=['София Петрова', 'Софья Петрова', 'София Петрова (Дореволюционная транскрипция)'], Arabic=['سوفيا بيتروفا', 'سوفيه بيتروفا', 'سوفيا بيتروفا (ترجمة معنوية)']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: حسن علي, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name حسن علي.\n",
            "\n",
            "User input name: حسن علي\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Husain Ali\", \"Hussain Aly\", \"Hussein Oli\"],\n",
            "    \"Cyrillic\": [\"Хусейн Али\", \"Хусин Али\", \"Хусын Оли\"],\n",
            "    \"Arabic\": [\"حسين علي\", \"حسين علي\", \"حسين علي\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Husain Ali\", \"Hussain Aly\", \"Hussein Oli\"],\n",
            "    \"Cyrillic\": [\"Хусейн Али\", \"Хусин Али\", \"Хусын Оли\"],\n",
            "    \"Arabic\": [\"حسين علي\", \"حسين علي\", \"حسين علي\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Husain Ali', 'Hussain Aly', 'Hussein Oli'], 'Cyrillic': ['Хусейн Али', 'Хусин Али', 'Хусын Оли'], 'Arabic': ['حسين علي', 'حسين علي', 'حسين علي']}}\n",
            "Parsed variations for حسن علي: Latin=['Husain Ali', 'Hussain Aly', 'Hussein Oli'], Cyrillic=['Хусейн Али', 'Хусин Али', 'Хусын Оли'], Arabic=['حسين علي', 'حسين علي', 'حسين علي']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Maria Gonzalez, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Maria Gonzalez.\n",
            "\n",
            "User input name: Maria Gonzalez\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Maria Gonzalez\", \"Maria Gonzalez-Maria\", \"Maria Gonzalez-Gonzalez\"],\n",
            "    \"Cyrillic\": [\"Мария Гонсалес\", \"Мария Гонсалез-Мария\", \"Мария Гонсалез-Гонсалез\"],\n",
            "    \"Arabic\": [\"ماريا كونزاليز\", \"ماريا كونزاليز-ماريا\", \"ماريا كونزاليز-كونزاليز\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Maria Gonzalez\", \"Maria Gonzalez-Maria\", \"Maria Gonzalez-Gonzalez\"],\n",
            "    \"Cyrillic\": [\"Мария Гонсалес\", \"Мария Гонсалез-Мария\", \"Мария Гонсалез-Гонсалез\"],\n",
            "    \"Arabic\": [\"ماريا كونزاليز\", \"ماريا كونزاليز-ماريا\", \"ماريا كونزاليز-كونزاليز\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Maria Gonzalez', 'Maria Gonzalez-Maria', 'Maria Gonzalez-Gonzalez'], 'Cyrillic': ['Мария Гонсалес', 'Мария Гонсалез-Мария', 'Мария Гонсалез-Гонсалез'], 'Arabic': ['ماريا كونزاليز', 'ماريا كونزاليز-ماريا', 'ماريا كونزاليز-كونزاليز']}}\n",
            "Parsed variations for Maria Gonzalez: Latin=['Maria Gonzalez', 'Maria Gonzalez-Maria', 'Maria Gonzalez-Gonzalez'], Cyrillic=['Мария Гонсалес', 'Мария Гонсалез-Мария', 'Мария Гонсалез-Гонсалез'], Arabic=['ماريا كونزاليز', 'ماريا كونزاليز-ماريا', 'ماريا كونزاليز-كونزاليز']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: خالد محمود, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name خالد محمود.\n",
            "\n",
            "User input name: خالد محمود\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Khalid Mohammed\", \"Khaled Mohammad\", \"Khaleed Mohammad\"],\n",
            "    \"Cyrillic\": [\"Халид Мухаммад\", \"Халед Мухаммад\", \"Халийд Мухаммад\"],\n",
            "    \"Arabic\": [\"خالد محمود\", \"خالد محمود\", \"خالد محمد\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Khalid Mohammed\", \"Khaled Mohammad\", \"Khaleed Mohammad\"],\n",
            "    \"Cyrillic\": [\"Халид Мухаммад\", \"Халед Мухаммад\", \"Халийд Мухаммад\"],\n",
            "    \"Arabic\": [\"خالد محمود\", \"خالد محمود\", \"خالد محمد\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Khalid Mohammed', 'Khaled Mohammad', 'Khaleed Mohammad'], 'Cyrillic': ['Халид Мухаммад', 'Халед Мухаммад', 'Халийд Мухаммад'], 'Arabic': ['خالد محمود', 'خالد محمود', 'خالد محمد']}}\n",
            "Parsed variations for خالد محمود: Latin=['Khalid Mohammed', 'Khaled Mohammad', 'Khaleed Mohammad'], Cyrillic=['Халид Мухаммад', 'Халед Мухаммад', 'Халийд Мухаммад'], Arabic=['خالد محمود', 'خالد محمود', 'خالد محمد']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Said, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Said.\n",
            "\n",
            "User input name: Said\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said\", \"Sayed\", \"Seid\"],\n",
            "    \"Cyrillic\": [\"Саид\", \"Сейд\", \"Сеид\"],\n",
            "    \"Arabic\": [\"سعيد\", \"سيد\", \"سعيد\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said\", \"Sayed\", \"Seid\"],\n",
            "    \"Cyrillic\": [\"Саид\", \"Сейд\", \"Сеид\"],\n",
            "    \"Arabic\": [\"سعيد\", \"سيد\", \"سعيد\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Said', 'Sayed', 'Seid'], 'Cyrillic': ['Саид', 'Сейд', 'Сеид'], 'Arabic': ['سعيد', 'سيد', 'سعيد']}}\n",
            "Parsed variations for Said: Latin=['Said', 'Sayed', 'Seid'], Cyrillic=['Саид', 'Сейд', 'Сеид'], Arabic=['سعيد', 'سيد', 'سعيد']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: Anna Kowalski, Raw output: Human: \n",
            "[INST] You are a multilingual name transliteration expert. Your task is to generate orthographic variations for a user-provided name Anna Kowalski.\n",
            "\n",
            "User input name: Anna Kowalski\n",
            "\n",
            "Instructions:\n",
            "1. Generate exactly three orthographic variations of the input name for each of the following scripts:\n",
            "   - Latin\n",
            "   - Cyrillic\n",
            "   - Arabic\n",
            "2. Ensure variations are plausible, culturally appropriate, and consistent with the input name.\n",
            "3. If the input name is ambiguous (e.g., a single name like \"Said\"), make reasonable assumptions about its origin or context to produce accurate transliterations.\n",
            "4. Do not invent names or scripts not requested.\n",
            "5. Output the result as a JSON object matching this schema:\n",
            "<bound method PydanticOutputParser.get_format_instructions of PydanticOutputParser(pydantic_object=<class '__main__.NameTransliterationOutput'>)>\n",
            "6. Do not include any text outside the JSON object.\n",
            "\n",
            "Examples:\n",
            "1. User input name: Aleksandr Petrov\n",
            "```json\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Alexander Petrov\", \"Alekzandr Petroff\", \"Alyaksandr Petrou\"],\n",
            "    \"Cyrillic\": [\"Александр Петров\", \"Александар Пятров\", \"Аляксандр Пятроў\"],\n",
            "    \"Arabic\": [\"ألكسندر بيتروف\", \"أليكسندر بيتروف\", \"أليكسندار بيتروف\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "\n",
            "2. User input name: فاطمة الزهراء\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Fatima Al-Zahra\", \"Faatimah Az-Zahraa\", \"Fatma Zahraa\"],\n",
            "    \"Cyrillic\": [\"Фатима Аз-Захра\", \"Фатма Аль-Захраа\", \"Фатыма Аз-Захра\"],\n",
            "    \"Arabic\": [\"فاطمة الزهراء\", \"فاطمه الزهراء\", \"فاطما الزهراء\"]\n",
            "  }\n",
            "}\n",
            "\n",
            "3. User input name: Саид Петр\n",
            "   {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Said Petr\", \"Sayed Pyotr\", \"Sayid Petar\"],\n",
            "    \"Cyrillic\": [\"Саид Пётр\", \"Сайд Петар\", \"Сайид Пьотр\"],\n",
            "    \"Arabic\": [\"سعيد بطرس\", \"سيد بطرس\", \"سعيّد بطرس\"]\n",
            "  }\n",
            "}\n",
            "[/INST]\n",
            "{\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Anna Kowalska\", \"Anna Kowalsky\", \"Anna Kowalscy\"],\n",
            "    \"Cyrillic\": [\"Анна Ковальская\", \"Анна Ковальский\", \"Анна Ковальскі\"],\n",
            "    \"Arabic\": [\"أننا كوالسكي\", \"أننا كوالسكي\", \"أننا كوالسكي\"]\n",
            "  }\n",
            "}\n",
            "Extracted JSON: {\n",
            "  \"Orthographic_Variations\": {\n",
            "    \"Latin\": [\"Anna Kowalska\", \"Anna Kowalsky\", \"Anna Kowalscy\"],\n",
            "    \"Cyrillic\": [\"Анна Ковальская\", \"Анна Ковальский\", \"Анна Ковальскі\"],\n",
            "    \"Arabic\": [\"أننا كوالسكي\", \"أننا كوالسكي\", \"أننا كوالسكي\"]\n",
            "  }\n",
            "}\n",
            "Parsed JSON: {'Orthographic_Variations': {'Latin': ['Anna Kowalska', 'Anna Kowalsky', 'Anna Kowalscy'], 'Cyrillic': ['Анна Ковальская', 'Анна Ковальский', 'Анна Ковальскі'], 'Arabic': ['أننا كوالسكي', 'أننا كوالسكي', 'أننا كوالسكي']}}\n",
            "Parsed variations for Anna Kowalski: Latin=['Anna Kowalska', 'Anna Kowalsky', 'Anna Kowalscy'], Cyrillic=['Анна Ковальская', 'Анна Ковальский', 'Анна Ковальскі'], Arabic=['أننا كوالسكي', 'أننا كوالسكي', 'أننا كوالسكي']\n",
            "Evaluation Results:\n",
            "                Input                                    Generated_Latin  \\\n",
            "0  mohamed naji dridi  Mohamed Naji Dridi, Mohamed N'Ji Dridi, Mohame...   \n",
            "1              Fatima                             Fatima, Fátima, Fatima   \n",
            "2    Aleksandr Ivanov  Aleksandr Ivanov, Alexander Ivanoff, Alekander...   \n",
            "3       عمر بن الخطاب  Omr bin Al-Khattab, Umar Ibn Al-Khattab, Umar ...   \n",
            "4       Sofia Petrova  Sofia Petrova, Sophia Petrov, Sofia Petrova (A...   \n",
            "5             حسن علي               Husain Ali, Hussain Aly, Hussein Oli   \n",
            "6      Maria Gonzalez  Maria Gonzalez, Maria Gonzalez-Maria, Maria Go...   \n",
            "7          خالد محمود  Khalid Mohammed, Khaled Mohammad, Khaleed Moha...   \n",
            "8                Said                                  Said, Sayed, Seid   \n",
            "9       Anna Kowalski        Anna Kowalska, Anna Kowalsky, Anna Kowalscy   \n",
            "\n",
            "                                  Generated_Cyrillic  \\\n",
            "0  Мохамед Нажи Дриди, Мохаммед Нажі Дриді, Мохам...   \n",
            "1                          Фатима, Фатьяма, Фатимаха   \n",
            "2  Александр Иванович, Александар Иванов, Алєксан...   \n",
            "3  Омар Ибн Аль-Хаттаб, Умар Ибн Аль-Хаттаб, Умар...   \n",
            "4  София Петрова, Софья Петрова, София Петрова (Д...   \n",
            "5                   Хусейн Али, Хусин Али, Хусын Оли   \n",
            "6  Мария Гонсалес, Мария Гонсалез-Мария, Мария Го...   \n",
            "7    Халид Мухаммад, Халед Мухаммад, Халийд Мухаммад   \n",
            "8                                   Саид, Сейд, Сеид   \n",
            "9   Анна Ковальская, Анна Ковальский, Анна Ковальскі   \n",
            "\n",
            "                                    Generated_Arabic  Levenshtein_Latin  \\\n",
            "0   محمد ناجي دريدي, محمد نجي دريدي, محمد ناجي دريدي           0.054581   \n",
            "1                                فاطمة, فاطمه, فاطما           0.055556   \n",
            "2  اَليكسانْدر إيْفَانْوْف, اليكسندر إيفانوف, الي...           0.151058   \n",
            "3        عمر بن الخطاب, عمر بن الخطاب, عمر بن الخطاب           0.140351   \n",
            "4  سوفيا بيتروفا, سوفيه بيتروفا, سوفيا بيتروفا (ت...           0.202381   \n",
            "5                       حسين علي, حسين علي, حسين علي           0.121212   \n",
            "6  ماريا كونزاليز, ماريا كونزاليز-ماريا, ماريا كو...           0.230435   \n",
            "7                  خالد محمود, خالد محمود, خالد محمد           0.281944   \n",
            "8                                    سعيد, سيد, سعيد           0.083333   \n",
            "9           أننا كوالسكي, أننا كوالسكي, أننا كوالسكي           0.102564   \n",
            "\n",
            "   Levenshtein_Cyrillic  Levenshtein_Arabic  BLEU_Latin  BLEU_Cyrillic  \\\n",
            "0              0.070175            0.022222    0.951862       0.954496   \n",
            "1              0.136905            0.000000    0.902369       0.821213   \n",
            "2              0.098312            0.157609    0.863120       0.907425   \n",
            "3              0.122807            0.000000    0.877930       0.862028   \n",
            "4              0.234848            0.267399    0.823802       0.769481   \n",
            "5              0.166667            0.125000    0.900216       0.827721   \n",
            "6              0.230435            0.340373    0.770949       0.770949   \n",
            "7              0.301587            0.033333    0.668114       0.597488   \n",
            "8              0.216667            0.000000    0.859117       0.597438   \n",
            "9              0.090476            0.083333    0.959019       0.963148   \n",
            "\n",
            "   BLEU_Arabic  Semantic_Latin  Semantic_Cyrillic  Semantic_Arabic  \\\n",
            "0     0.964845        0.969958           0.987569         0.987834   \n",
            "1     1.000000        0.981791           0.900399         1.000000   \n",
            "2     0.811713        0.934316           0.905452         0.918217   \n",
            "3     1.000000        0.934756           0.988959         1.000000   \n",
            "4     0.760044        0.915066           0.924158         0.917409   \n",
            "5     0.790569        0.828873           0.852037         0.570955   \n",
            "6     0.677154        0.978199           0.959089         0.931434   \n",
            "7     0.945682        0.849077           0.946352         0.977665   \n",
            "8     1.000000        0.912679           0.928703         1.000000   \n",
            "9     0.912871        0.982673           0.955829         0.691032   \n",
            "\n",
            "   Phonetic_Latin  Phonetic_Cyrillic  Phonetic_Arabic  Self_BLEU_Latin  \\\n",
            "0        1.000000                1.0         1.000000         0.836484   \n",
            "1        1.000000                1.0         1.000000         0.804738   \n",
            "2        0.833333                1.0         0.833333         0.705895   \n",
            "3        1.000000                1.0         1.000000         0.813087   \n",
            "4        1.000000                1.0         1.000000         0.537586   \n",
            "5        1.000000                1.0         1.000000         0.671695   \n",
            "6        1.000000                1.0         1.000000         0.652382   \n",
            "7        1.000000                1.0         1.000000         0.864268   \n",
            "8        1.000000                1.0         1.000000         0.344095   \n",
            "9        1.000000                1.0         1.000000         0.878881   \n",
            "\n",
            "   Self_BLEU_Cyrillic  Self_BLEU_Arabic  Format_Correct  \n",
            "0            0.825772          0.929654               1  \n",
            "1            0.615696          0.774597               1  \n",
            "2            0.720351          0.647677               1  \n",
            "3            0.909019          1.000000               1  \n",
            "4            0.472015          0.576575               1  \n",
            "5            0.637424          1.000000               1  \n",
            "6            0.627426          0.659207               1  \n",
            "7            0.868677          0.891364               1  \n",
            "8            0.384001          0.668888               1  \n",
            "9            0.861962          1.000000               1  \n",
            "\n",
            "Average Metrics:\n",
            "Avg_Levenshtein_Latin: 0.14\n",
            "Avg_Levenshtein_Cyrillic: 0.17\n",
            "Avg_Levenshtein_Arabic: 0.10\n",
            "Avg_BLEU_Latin: 0.86\n",
            "Avg_BLEU_Cyrillic: 0.81\n",
            "Avg_BLEU_Arabic: 0.89\n",
            "Avg_Semantic_Latin: 0.93\n",
            "Avg_Semantic_Cyrillic: 0.93\n",
            "Avg_Semantic_Arabic: 0.90\n",
            "Avg_Phonetic_Latin: 0.98\n",
            "Avg_Phonetic_Cyrillic: 1.00\n",
            "Avg_Phonetic_Arabic: 0.98\n",
            "Avg_Self_BLEU_Latin: 0.71\n",
            "Avg_Self_BLEU_Cyrillic: 0.69\n",
            "Avg_Self_BLEU_Arabic: 0.81\n",
            "Format_Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from Levenshtein import distance\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import itertools\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import json\n",
        "import re\n",
        "from fuzzy import DMetaphone\n",
        "import unidecode\n",
        "\n",
        "# Initialize metrics\n",
        "st_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "smoothie = SmoothingFunction().method4\n",
        "dm = DMetaphone()\n",
        "\n",
        "def evaluate_prompt(llm, prompt_template, test_dataset, output_parser):\n",
        "    results = []\n",
        "\n",
        "    for test_case in test_dataset:\n",
        "        input_name = test_case[\"input\"]\n",
        "        ground_truth = test_case[\"ground_truth\"]\n",
        "\n",
        "        # Generate output\n",
        "        formatted_prompt = prompt_template.format(name=input_name)\n",
        "        messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "        raw_output = llm.invoke(messages)\n",
        "        print(f\"Input: {input_name}, Raw output: {raw_output}\")\n",
        "\n",
        "        # Extract the last JSON object\n",
        "        try:\n",
        "            # Find all JSON-like blocks\n",
        "            json_matches = re.findall(r'\\{(?:[^{}]|\\{[^{}]*\\})*\\}', raw_output, re.DOTALL)\n",
        "            if not json_matches:\n",
        "                raise ValueError(\"No JSON found in output\")\n",
        "            # Take the last JSON (model's output, not examples)\n",
        "            json_str = json_matches[-1]\n",
        "            print(f\"Extracted JSON: {json_str}\")\n",
        "\n",
        "            # Parse JSON\n",
        "            parsed_json = json.loads(json_str)\n",
        "            print(f\"Parsed JSON: {parsed_json}\")\n",
        "\n",
        "            # Pydantic parsing\n",
        "            parsed_output = output_parser.parse(json_str)\n",
        "            variations = parsed_output.Orthographic_Variations\n",
        "            latin = variations.Latin\n",
        "            cyrillic = variations.Cyrillic\n",
        "            arabic = variations.Arabic\n",
        "            print(f\"Parsed variations for {input_name}: Latin={latin}, Cyrillic={cyrillic}, Arabic={arabic}\")\n",
        "\n",
        "            # Verify consistency\n",
        "            if (latin != parsed_json[\"Orthographic_Variations\"][\"Latin\"] or\n",
        "                cyrillic != parsed_json[\"Orthographic_Variations\"][\"Cyrillic\"] or\n",
        "                arabic != parsed_json[\"Orthographic_Variations\"][\"Arabic\"]):\n",
        "                print(f\"Warning: Pydantic parsed output does not match manual JSON for {input_name}\")\n",
        "\n",
        "            format_score = 1 if (len(latin) == 3 and len(cyrillic) == 3 and len(arabic) == 3) else 0\n",
        "        except (ValueError, OutputParserException, json.JSONDecodeError, KeyError) as e:\n",
        "            print(f\"Parsing error for {input_name}: {e}\")\n",
        "            # Fallback to manual parsing\n",
        "            try:\n",
        "                latin = parsed_json[\"Orthographic_Variations\"][\"Latin\"]\n",
        "                cyrillic = parsed_json[\"Orthographic_Variations\"][\"Cyrillic\"]\n",
        "                arabic = parsed_json[\"Orthographic_Variations\"][\"Arabic\"]\n",
        "                format_score = 1 if (len(latin) == 3 and len(cyrillic) == 3 and len(arabic) == 3) else 0\n",
        "                print(f\"Fallback parsing successful: Latin={latin}, Cyrillic={cyrillic}, Arabic={arabic}\")\n",
        "            except (KeyError, NameError):\n",
        "                latin, cyrillic, arabic = [], [], []\n",
        "                format_score = 0\n",
        "\n",
        "        # Tokenize for BLEU/Self-BLEU (character-level)\n",
        "        def tokenize(text):\n",
        "            return list(text)  # Character-level for names\n",
        "\n",
        "        # Levenshtein scores\n",
        "        levenshtein_scores = {\n",
        "            \"Latin\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Latin\"]) for gen in latin] or [1.0],\n",
        "            \"Cyrillic\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Cyrillic\"]) for gen in cyrillic] or [1.0],\n",
        "            \"Arabic\": [min(distance(gen, gt) / max(len(gen), len(gt), 1) for gt in ground_truth[\"Arabic\"]) for gen in arabic] or [1.0]\n",
        "        }\n",
        "\n",
        "        # NLTK BLEU scores\n",
        "        bleu_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                gen_tokens = tokenize(g)\n",
        "                gt_tokens_list = [tokenize(gt) for gt in gt_list]\n",
        "                bleu_score = sentence_bleu(\n",
        "                    gt_tokens_list,\n",
        "                    gen_tokens,\n",
        "                    weights=(0.5, 0.5, 0, 0),\n",
        "                    smoothing_function=smoothie\n",
        "                )\n",
        "                bleu_scores[script].append(bleu_score)\n",
        "\n",
        "        # Semantic similarity\n",
        "        semantic_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                g_emb = st_model.encode(g, convert_to_tensor=True)\n",
        "                gt_embs = [st_model.encode(gt, convert_to_tensor=True) for gt in gt_list]\n",
        "                sem_score = max(float(util.cos_sim(g_emb, gt_emb)) for gt_emb in gt_embs)\n",
        "                semantic_scores[script].append(sem_score)\n",
        "\n",
        "        # Phonetic similarity\n",
        "        def phonetic_similarity(s1, s2, script):\n",
        "            s1_lat = unidecode.unidecode(s1) if script in [\"Cyrillic\", \"Arabic\"] else s1\n",
        "            s2_lat = unidecode.unidecode(s2) if script in [\"Cyrillic\", \"Arabic\"] else s2\n",
        "            if not s1_lat or not s2_lat:\n",
        "                return 0.0\n",
        "            code1, code2 = dm(s1_lat.encode('utf-8').decode('ascii', errors='ignore'))[0], dm(s2_lat.encode('utf-8').decode('ascii', errors='ignore'))[0]\n",
        "            if not code1 or not code2:\n",
        "                return 0.0\n",
        "            return 1.0 if code1 == code2 else 0.5 if len(set(code1) & set(code2)) > 0 else 0.0\n",
        "\n",
        "        phonetic_scores = {\n",
        "            \"Latin\": [max(phonetic_similarity(gen, gt, \"Latin\") for gt in ground_truth[\"Latin\"]) for gen in latin] or [0.0],\n",
        "            \"Cyrillic\": [max(phonetic_similarity(gen, gt, \"Cyrillic\") for gt in ground_truth[\"Cyrillic\"]) for gen in cyrillic] or [0.0],\n",
        "            \"Arabic\": [max(phonetic_similarity(gen, gt, \"Arabic\") for gt in ground_truth[\"Arabic\"]) for gen in arabic] or [0.0]\n",
        "        }\n",
        "\n",
        "        # Self-BLEU\n",
        "        self_bleu_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen_list, script in [(latin, \"Latin\"), (cyrillic, \"Cyrillic\"), (arabic, \"Arabic\")]:\n",
        "            if len(gen_list) >= 2:\n",
        "                pairs = list(itertools.combinations(gen_list, 2))\n",
        "                for g1, g2 in pairs:\n",
        "                    tokens1, tokens2 = tokenize(g1), tokenize(g2)\n",
        "                    score = sentence_bleu([tokens1], tokens2, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
        "                    self_bleu_scores[script].append(score)\n",
        "            else:\n",
        "                self_bleu_scores[script].append(1.0)\n",
        "\n",
        "        avg_metrics = {\n",
        "            \"Levenshtein_Latin\": sum(levenshtein_scores[\"Latin\"]) / max(len(levenshtein_scores[\"Latin\"]), 1),\n",
        "            \"Levenshtein_Cyrillic\": sum(levenshtein_scores[\"Cyrillic\"]) / max(len(levenshtein_scores[\"Cyrillic\"]), 1),\n",
        "            \"Levenshtein_Arabic\": sum(levenshtein_scores[\"Arabic\"]) / max(len(levenshtein_scores[\"Arabic\"]), 1),\n",
        "            \"BLEU_Latin\": sum(bleu_scores[\"Latin\"]) / max(len(bleu_scores[\"Latin\"]), 1),\n",
        "            \"BLEU_Cyrillic\": sum(bleu_scores[\"Cyrillic\"]) / max(len(bleu_scores[\"Cyrillic\"]), 1),\n",
        "            \"BLEU_Arabic\": sum(bleu_scores[\"Arabic\"]) / max(len(bleu_scores[\"Arabic\"]), 1),\n",
        "            \"Semantic_Latin\": sum(semantic_scores[\"Latin\"]) / max(len(semantic_scores[\"Latin\"]), 1),\n",
        "            \"Semantic_Cyrillic\": sum(semantic_scores[\"Cyrillic\"]) / max(len(semantic_scores[\"Cyrillic\"]), 1),\n",
        "            \"Semantic_Arabic\": sum(semantic_scores[\"Arabic\"]) / max(len(semantic_scores[\"Arabic\"]), 1),\n",
        "            \"Phonetic_Latin\": sum(phonetic_scores[\"Latin\"]) / max(len(phonetic_scores[\"Latin\"]), 1),\n",
        "            \"Phonetic_Cyrillic\": sum(phonetic_scores[\"Cyrillic\"]) / max(len(phonetic_scores[\"Cyrillic\"]), 1),\n",
        "            \"Phonetic_Arabic\": sum(phonetic_scores[\"Arabic\"]) / max(len(phonetic_scores[\"Arabic\"]), 1),\n",
        "            \"Self_BLEU_Latin\": sum(self_bleu_scores[\"Latin\"]) / max(len(self_bleu_scores[\"Latin\"]), 1) if self_bleu_scores[\"Latin\"] else 1.0,\n",
        "            \"Self_BLEU_Cyrillic\": sum(self_bleu_scores[\"Cyrillic\"]) / max(len(self_bleu_scores[\"Cyrillic\"]), 1) if self_bleu_scores[\"Cyrillic\"] else 1.0,\n",
        "            \"Self_BLEU_Arabic\": sum(self_bleu_scores[\"Arabic\"]) / max(len(self_bleu_scores[\"Arabic\"]), 1) if self_bleu_scores[\"Arabic\"] else 1.0\n",
        "        }\n",
        "\n",
        "        results.append({\n",
        "            \"Input\": input_name,\n",
        "            \"Generated_Latin\": \", \".join(latin),\n",
        "            \"Generated_Cyrillic\": \", \".join(cyrillic),\n",
        "            \"Generated_Arabic\": \", \".join(arabic),\n",
        "            \"Levenshtein_Latin\": avg_metrics[\"Levenshtein_Latin\"],\n",
        "            \"Levenshtein_Cyrillic\": avg_metrics[\"Levenshtein_Cyrillic\"],\n",
        "            \"Levenshtein_Arabic\": avg_metrics[\"Levenshtein_Arabic\"],\n",
        "            \"BLEU_Latin\": avg_metrics[\"BLEU_Latin\"],\n",
        "            \"BLEU_Cyrillic\": avg_metrics[\"BLEU_Cyrillic\"],\n",
        "            \"BLEU_Arabic\": avg_metrics[\"BLEU_Arabic\"],\n",
        "            \"Semantic_Latin\": avg_metrics[\"Semantic_Latin\"],\n",
        "            \"Semantic_Cyrillic\": avg_metrics[\"Semantic_Cyrillic\"],\n",
        "            \"Semantic_Arabic\": avg_metrics[\"Semantic_Arabic\"],\n",
        "            \"Phonetic_Latin\": avg_metrics[\"Phonetic_Latin\"],\n",
        "            \"Phonetic_Cyrillic\": avg_metrics[\"Phonetic_Cyrillic\"],\n",
        "            \"Phonetic_Arabic\": avg_metrics[\"Phonetic_Arabic\"],\n",
        "            \"Self_BLEU_Latin\": avg_metrics[\"Self_BLEU_Latin\"],\n",
        "            \"Self_BLEU_Cyrillic\": avg_metrics[\"Self_BLEU_Cyrillic\"],\n",
        "            \"Self_BLEU_Arabic\": avg_metrics[\"Self_BLEU_Arabic\"],\n",
        "            \"Format_Correct\": format_score\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    avg_metrics = {\n",
        "        \"Avg_Levenshtein_Latin\": df[\"Levenshtein_Latin\"].mean(),\n",
        "        \"Avg_Levenshtein_Cyrillic\": df[\"Levenshtein_Cyrillic\"].mean(),\n",
        "        \"Avg_Levenshtein_Arabic\": df[\"Levenshtein_Arabic\"].mean(),\n",
        "        \"Avg_BLEU_Latin\": df[\"BLEU_Latin\"].mean(),\n",
        "        \"Avg_BLEU_Cyrillic\": df[\"BLEU_Cyrillic\"].mean(),\n",
        "        \"Avg_BLEU_Arabic\": df[\"BLEU_Arabic\"].mean(),\n",
        "        \"Avg_Semantic_Latin\": df[\"Semantic_Latin\"].mean(),\n",
        "        \"Avg_Semantic_Cyrillic\": df[\"Semantic_Cyrillic\"].mean(),\n",
        "        \"Avg_Semantic_Arabic\": df[\"Semantic_Arabic\"].mean(),\n",
        "        \"Avg_Phonetic_Latin\": df[\"Phonetic_Latin\"].mean(),\n",
        "        \"Avg_Phonetic_Cyrillic\": df[\"Phonetic_Cyrillic\"].mean(),\n",
        "        \"Avg_Phonetic_Arabic\": df[\"Phonetic_Arabic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Latin\": df[\"Self_BLEU_Latin\"].mean(),\n",
        "        \"Avg_Self_BLEU_Cyrillic\": df[\"Self_BLEU_Cyrillic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Arabic\": df[\"Self_BLEU_Arabic\"].mean(),\n",
        "        \"Format_Accuracy\": df[\"Format_Correct\"].mean()\n",
        "    }\n",
        "\n",
        "    return df, avg_metrics\n",
        "\n",
        "\n",
        "# Run evaluation\n",
        "df_results, avg_metrics = evaluate_prompt(llm, prompt_template, test_dataset, output_parser)\n",
        "df_results.to_csv(\"prompt_evaluation_fixed_parsing.csv\", index=False)\n",
        "\n",
        "print(\"Evaluation Results:\")\n",
        "print(df_results)\n",
        "print(\"\\nAverage Metrics:\")\n",
        "for k, v in avg_metrics.items():\n",
        "    print(f\"{k}: {v:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#update the levenshtein with jaro_winkler\n"
      ],
      "metadata": {
        "id": "d8iDRKuzRqqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from Levenshtein import distance, jaro_winkler\n",
        "from langchain_core.exceptions import OutputParserException\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import itertools\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import json\n",
        "import re\n",
        "from fuzzy import DMetaphone\n",
        "import unidecode\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Initialize metrics\n",
        "st_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "smoothie = SmoothingFunction().method4\n",
        "dm = DMetaphone()\n",
        "\n",
        "# Prompt (unchanged)\n",
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"name\"],\n",
        "    template=\"\"\"You are a multilingual name transliteration expert. Generate **exactly three distinct** orthographic variations for the name '{name}' in Latin, Cyrillic, and Arabic scripts. Each variation must differ in spelling, diacritics, or transliteration style, be culturally appropriate, and phonetically consistent with the input. Avoid identical or near-identical outputs. Do not add patronymics or modify the name structure unless present in the input. Avoid incorrect substitutions (e.g., 'محمود' for 'محمد'). Output as JSON:\n",
        "{{\n",
        "  \"Orthographic_Variations\": {{\n",
        "    \"Latin\": [],\n",
        "    \"Cyrillic\": [],\n",
        "    \"Arabic\": []\n",
        "  }}\n",
        "}}\n",
        "Examples:\n",
        "1. Name: Mohamed\n",
        "{{\n",
        "  \"Orthographic_Variations\": {{\n",
        "    \"Latin\": [\"Mohamed\", \"Mohammad\", \"Muhammad\"],\n",
        "    \"Cyrillic\": [\"Мохамед\", \"Мохаммад\", \"Мухаммад\"],\n",
        "    \"Arabic\": [\"محمد\", \"محمّد\", \"مُحمد\"]\n",
        "  }}\n",
        "}}\n",
        "2. Name: فاطمة\n",
        "{{\n",
        "  \"Orthographic_Variations\": {{\n",
        "    \"Latin\": [\"Fatima\", \"Faatimah\", \"Fatma\"],\n",
        "    \"Cyrillic\": [\"Фатима\", \"Фатыма\", \"Фатма\"],\n",
        "    \"Arabic\": [\"فاطمة\", \"فاطمه\", \"فاطما\"]\n",
        "  }}\n",
        "}}\"\"\"\n",
        ")\n",
        "\n",
        "def evaluate_prompt(llm, prompt_template, test_dataset, output_parser, use_cer=False, use_jaro_winkler=True, keep_levenshtein=False):\n",
        "    results = []\n",
        "\n",
        "    for test_case in test_dataset:\n",
        "        input_name = test_case[\"input\"]\n",
        "        ground_truth = test_case[\"ground_truth\"]\n",
        "\n",
        "        # Generate output\n",
        "        formatted_prompt = prompt_template.format(name=input_name)\n",
        "        messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
        "        raw_output = llm.invoke(messages)\n",
        "        print(f\"Input: {input_name}, Raw output: {raw_output}\")\n",
        "\n",
        "        # Extract JSON\n",
        "        try:\n",
        "            json_matches = re.findall(r'\\{(?:[^{}]|\\{[^{}]*\\})*\\}', raw_output, re.DOTALL)\n",
        "            if not json_matches:\n",
        "                raise ValueError(\"No JSON found in output\")\n",
        "            json_str = json_matches[-1]\n",
        "            print(f\"Extracted JSON: {json_str}\")\n",
        "\n",
        "            parsed_json = json.loads(json_str)\n",
        "            print(f\"Parsed JSON: {parsed_json}\")\n",
        "\n",
        "            parsed_output = output_parser.parse(json_str)\n",
        "            variations = parsed_output.Orthographic_Variations\n",
        "            latin = variations.Latin\n",
        "            cyrillic = variations.Cyrillic\n",
        "            arabic = variations.Arabic\n",
        "            print(f\"Parsed variations for {input_name}: Latin={latin}, Cyrillic={cyrillic}, Arabic={arabic}\")\n",
        "\n",
        "            format_score = 1 if (len(latin) == 3 and len(cyrillic) == 3 and len(arabic) == 3) else 0\n",
        "        except (ValueError, OutputParserException, json.JSONDecodeError, KeyError) as e:\n",
        "            print(f\"Parsing error for {input_name}: {e}\")\n",
        "            try:\n",
        "                latin = parsed_json[\"Orthographic_Variations\"][\"Latin\"]\n",
        "                cyrillic = parsed_json[\"Orthographic_Variations\"][\"Cyrillic\"]\n",
        "                arabic = parsed_json[\"Orthographic_Variations\"][\"Arabic\"]\n",
        "                format_score = 1 if (len(latin) == 3 and len(cyrillic) == 3 and len(arabic) == 3) else 0\n",
        "            except (KeyError, NameError):\n",
        "                latin, cyrillic, arabic = [], [], []\n",
        "                format_score = 0\n",
        "\n",
        "        # Tokenize for BLEU/Self-BLEU\n",
        "        def tokenize(text):\n",
        "            return list(text)\n",
        "\n",
        "        # Edit distance scores (Jaro-Winkler similarity or Levenshtein dissimilarity)\n",
        "        edit_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        levenshtein_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []} if keep_levenshtein else None\n",
        "\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                if use_jaro_winkler:\n",
        "                    # Jaro-Winkler similarity (higher = better)\n",
        "                    jw_scores = [jaro_winkler(g, gt) for gt in gt_list]\n",
        "                    edit_scores[script].append(max(jw_scores) if jw_scores else 0.0)\n",
        "                else:\n",
        "                    # Normalized Levenshtein dissimilarity\n",
        "                    lev_scores = [distance(g, gt) / max(len(g), len(gt), 1) for gt in gt_list]\n",
        "                    edit_scores[script].append(1.0 - min(lev_scores) if lev_scores else 0.0)  # Convert to similarity\n",
        "\n",
        "                if keep_levenshtein:\n",
        "                    lev_scores = [distance(g, gt) / max(len(g), len(gt), 1) for gt in gt_list]\n",
        "                    levenshtein_scores[script].append(min(lev_scores) if lev_scores else 1.0)\n",
        "\n",
        "        # BLEU or CER scores\n",
        "        if use_cer:\n",
        "            def cer(reference, hypothesis):\n",
        "                return distance(reference, hypothesis) / max(len(reference), 1)\n",
        "\n",
        "            similarity_scores = {\n",
        "                \"Latin\": [1.0 - min(cer(gen, gt) for gt in ground_truth[\"Latin\"]) for gen in latin] or [0.0],\n",
        "                \"Cyrillic\": [1.0 - min(cer(gen, gt) for gt in ground_truth[\"Cyrillic\"]) for gen in cyrillic] or [0.0],\n",
        "                \"Arabic\": [1.0 - min(cer(gen, gt) for gt in ground_truth[\"Arabic\"]) for gen in arabic] or [0.0]\n",
        "            }\n",
        "            score_type = \"CER\"\n",
        "        else:\n",
        "            similarity_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "            for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "                script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "                for g in gen:\n",
        "                    gen_tokens = tokenize(g)\n",
        "                    gt_tokens_list = [tokenize(gt) for gt in gt_list]\n",
        "                    bleu_score = sentence_bleu(\n",
        "                        gt_tokens_list,\n",
        "                        gen_tokens,\n",
        "                        weights=(0.5, 0.5, 0, 0),\n",
        "                        smoothing_function=smoothie\n",
        "                    )\n",
        "                    similarity_scores[script].append(bleu_score)\n",
        "            score_type = \"BLEU\"\n",
        "\n",
        "        # Semantic similarity\n",
        "        semantic_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen, gt_list in [(latin, ground_truth[\"Latin\"]), (cyrillic, ground_truth[\"Cyrillic\"]), (arabic, ground_truth[\"Arabic\"])]:\n",
        "            script = \"Latin\" if gt_list is ground_truth[\"Latin\"] else \"Cyrillic\" if gt_list is ground_truth[\"Cyrillic\"] else \"Arabic\"\n",
        "            for g in gen:\n",
        "                g_emb = st_model.encode(g, convert_to_tensor=True)\n",
        "                gt_embs = [st_model.encode(gt, convert_to_tensor=True) for gt in gt_list]\n",
        "                sem_score = max(float(util.cos_sim(g_emb, gt_emb)) for gt_emb in gt_embs)\n",
        "                semantic_scores[script].append(sem_score)\n",
        "\n",
        "        # DMetaphone-based phonetic similarity\n",
        "        def phonetic_similarity_dmetaphone(s1, s2, script):\n",
        "            mappings = {\n",
        "                \"Arabic\": {\n",
        "                    \"محمد\": \"mohamed\", \"محمّد\": \"mohamed\", \"مُحمد\": \"mohamed\",\n",
        "                    \"محمود\": \"mahmoud\", \"فاطمة\": \"fatima\", \"فاطمه\": \"fatima\", \"فاطما\": \"fatima\"\n",
        "                }\n",
        "            }\n",
        "            if script in mappings:\n",
        "                s1_lat = mappings[script].get(s1, unidecode.unidecode(s1))\n",
        "                s2_lat = mappings[script].get(s2, unidecode.unidecode(s2))\n",
        "            else:\n",
        "                s1_lat = unidecode.unidecode(s1) if script in [\"Cyrillic\", \"Arabic\"] else s1\n",
        "                s2_lat = unidecode.unidecode(s2) if script in [\"Cyrillic\", \"Arabic\"] else s2\n",
        "            if not s1_lat or not s2_lat:\n",
        "                return 0.0\n",
        "            code1, code2 = dm(s1_lat)[0], dm(s2_lat)[0]\n",
        "            if not code1 or not code2:\n",
        "                return 0.0\n",
        "            return 1.0 if code1 == code2 else 0.5 if len(set(code1) & set(code2)) > 0 else 0.0\n",
        "\n",
        "        dmetaphone_scores = {\n",
        "            \"Latin\": [max(phonetic_similarity_dmetaphone(gen, gt, \"Latin\") for gt in ground_truth[\"Latin\"]) for gen in latin] or [0.0],\n",
        "            \"Cyrillic\": [max(phonetic_similarity_dmetaphone(gen, gt, \"Cyrillic\") for gt in ground_truth[\"Cyrillic\"]) for gen in cyrillic] or [0.0],\n",
        "            \"Arabic\": [max(phonetic_similarity_dmetaphone(gen, gt, \"Arabic\") for gt in ground_truth[\"Arabic\"]) for gen in arabic] or [0.0]\n",
        "        }\n",
        "\n",
        "        # Self-BLEU\n",
        "        self_bleu_scores = {\"Latin\": [], \"Cyrillic\": [], \"Arabic\": []}\n",
        "        for gen_list, script in [(latin, \"Latin\"), (cyrillic, \"Cyrillic\"), (arabic, \"Arabic\")]:\n",
        "            if len(gen_list) >= 2:\n",
        "                pairs = list(itertools.combinations(gen_list, 2))\n",
        "                for g1, g2 in pairs:\n",
        "                    tokens1, tokens2 = tokenize(g1), tokenize(g2)\n",
        "                    score = sentence_bleu([tokens1], tokens2, weights=(0.5, 0.5, 0, 0), smoothing_function=smoothie)\n",
        "                    self_bleu_scores[script].append(score)\n",
        "            else:\n",
        "                self_bleu_scores[script].append(1.0)\n",
        "\n",
        "        # Prepare average metrics\n",
        "        avg_metrics = {\n",
        "            f\"{score_type}_Latin\": sum(similarity_scores[\"Latin\"]) / max(len(similarity_scores[\"Latin\"]), 1),\n",
        "            f\"{score_type}_Cyrillic\": sum(similarity_scores[\"Cyrillic\"]) / max(len(similarity_scores[\"Cyrillic\"]), 1),\n",
        "            f\"{score_type}_Arabic\": sum(similarity_scores[\"Arabic\"]) / max(len(similarity_scores[\"Arabic\"]), 1),\n",
        "            \"Semantic_Latin\": sum(semantic_scores[\"Latin\"]) / max(len(semantic_scores[\"Latin\"]), 1),\n",
        "            \"Semantic_Cyrillic\": sum(semantic_scores[\"Cyrillic\"]) / max(len(semantic_scores[\"Cyrillic\"]), 1),\n",
        "            \"Semantic_Arabic\": sum(semantic_scores[\"Arabic\"]) / max(len(semantic_scores[\"Arabic\"]), 1),\n",
        "            \"Phonetic_Latin\": sum(dmetaphone_scores[\"Latin\"]) / max(len(dmetaphone_scores[\"Latin\"]), 1),\n",
        "            \"Phonetic_Cyrillic\": sum(dmetaphone_scores[\"Cyrillic\"]) / max(len(dmetaphone_scores[\"Cyrillic\"]), 1),\n",
        "            \"Phonetic_Arabic\": sum(dmetaphone_scores[\"Arabic\"]) / max(len(dmetaphone_scores[\"Arabic\"]), 1),\n",
        "            \"Self_BLEU_Latin\": sum(self_bleu_scores[\"Latin\"]) / max(len(self_bleu_scores[\"Latin\"]), 1) if self_bleu_scores[\"Latin\"] else 1.0,\n",
        "            \"Self_BLEU_Cyrillic\": sum(self_bleu_scores[\"Cyrillic\"]) / max(len(self_bleu_scores[\"Cyrillic\"]), 1) if self_bleu_scores[\"Cyrillic\"] else 1.0,\n",
        "            \"Self_BLEU_Arabic\": sum(self_bleu_scores[\"Arabic\"]) / max(len(self_bleu_scores[\"Arabic\"]), 1) if self_bleu_scores[\"Arabic\"] else 1.0\n",
        "        }\n",
        "\n",
        "        # Add edit distance metrics\n",
        "        edit_metric_name = \"JaroWinklerSimilarity\" if use_jaro_winkler else \"LevenshteinSimilarity\"\n",
        "        avg_metrics.update({\n",
        "            f\"{edit_metric_name}_Latin\": sum(edit_scores[\"Latin\"]) / max(len(edit_scores[\"Latin\"]), 1),\n",
        "            f\"{edit_metric_name}_Cyrillic\": sum(edit_scores[\"Cyrillic\"]) / max(len(edit_scores[\"Cyrillic\"]), 1),\n",
        "            f\"{edit_metric_name}_Arabic\": sum(edit_scores[\"Arabic\"]) / max(len(edit_scores[\"Arabic\"]), 1)\n",
        "        })\n",
        "\n",
        "        if keep_levenshtein:\n",
        "            avg_metrics.update({\n",
        "                \"LevenshteinDissimilarity_Latin\": sum(levenshtein_scores[\"Latin\"]) / max(len(levenshtein_scores[\"Latin\"]), 1),\n",
        "                \"LevenshteinDissimilarity_Cyrillic\": sum(levenshtein_scores[\"Cyrillic\"]) / max(len(levenshtein_scores[\"Cyrillic\"]), 1),\n",
        "                \"LevenshteinDissimilarity_Arabic\": sum(levenshtein_scores[\"Arabic\"]) / max(len(levenshtein_scores[\"Arabic\"]), 1)\n",
        "            })\n",
        "\n",
        "        # Prepare result row\n",
        "        result = {\n",
        "            \"Input\": input_name,\n",
        "            \"Generated_Latin\": \", \".join(latin),\n",
        "            \"Generated_Cyrillic\": \", \".join(cyrillic),\n",
        "            \"Generated_Arabic\": \", \".join(arabic),\n",
        "            f\"{edit_metric_name}_Latin\": avg_metrics[f\"{edit_metric_name}_Latin\"],\n",
        "            f\"{edit_metric_name}_Cyrillic\": avg_metrics[f\"{edit_metric_name}_Cyrillic\"],\n",
        "            f\"{edit_metric_name}_Arabic\": avg_metrics[f\"{edit_metric_name}_Arabic\"],\n",
        "            f\"{score_type}_Latin\": avg_metrics[f\"{score_type}_Latin\"],\n",
        "            f\"{score_type}_Cyrillic\": avg_metrics[f\"{score_type}_Cyrillic\"],\n",
        "            f\"{score_type}_Arabic\": avg_metrics[f\"{score_type}_Arabic\"],\n",
        "            \"Semantic_Latin\": avg_metrics[\"Semantic_Latin\"],\n",
        "            \"Semantic_Cyrillic\": avg_metrics[\"Semantic_Cyrillic\"],\n",
        "            \"Semantic_Arabic\": avg_metrics[\"Semantic_Arabic\"],\n",
        "            \"Phonetic_Latin\": avg_metrics[\"Phonetic_Latin\"],\n",
        "            \"Phonetic_Cyrillic\": avg_metrics[\"Phonetic_Cyrillic\"],\n",
        "            \"Phonetic_Arabic\": avg_metrics[\"Phonetic_Arabic\"],\n",
        "            \"Self_BLEU_Latin\": avg_metrics[\"Self_BLEU_Latin\"],\n",
        "            \"Self_BLEU_Cyrillic\": avg_metrics[\"Self_BLEU_Cyrillic\"],\n",
        "            \"Self_BLEU_Arabic\": avg_metrics[\"Self_BLEU_Arabic\"],\n",
        "            \"Format_Correct\": format_score\n",
        "        }\n",
        "\n",
        "        if keep_levenshtein:\n",
        "            result.update({\n",
        "                \"LevenshteinDissimilarity_Latin\": avg_metrics[\"LevenshteinDissimilarity_Latin\"],\n",
        "                \"LevenshteinDissimilarity_Cyrillic\": avg_metrics[\"LevenshteinDissimilarity_Cyrillic\"],\n",
        "                \"LevenshteinDissimilarity_Arabic\": avg_metrics[\"LevenshteinDissimilarity_Arabic\"]\n",
        "            })\n",
        "\n",
        "        results.append(result)\n",
        "\n",
        "    df = pd.DataFrame(results)\n",
        "    avg_metrics = {\n",
        "        f\"Avg_{edit_metric_name}_Latin\": df[f\"{edit_metric_name}_Latin\"].mean(),\n",
        "        f\"Avg_{edit_metric_name}_Cyrillic\": df[f\"{edit_metric_name}_Cyrillic\"].mean(),\n",
        "        f\"Avg_{edit_metric_name}_Arabic\": df[f\"{edit_metric_name}_Arabic\"].mean(),\n",
        "        f\"Avg_{score_type}_Latin\": df[f\"{score_type}_Latin\"].mean(),\n",
        "        f\"Avg_{score_type}_Cyrillic\": df[f\"{score_type}_Cyrillic\"].mean(),\n",
        "        f\"Avg_{score_type}_Arabic\": df[f\"{score_type}_Arabic\"].mean(),\n",
        "        \"Avg_Semantic_Latin\": df[\"Semantic_Latin\"].mean(),\n",
        "        \"Avg_Semantic_Cyrillic\": df[\"Semantic_Cyrillic\"].mean(),\n",
        "        \"Avg_Semantic_Arabic\": df[\"Semantic_Arabic\"].mean(),\n",
        "        \"Avg_Phonetic_Latin\": df[\"Phonetic_Latin\"].mean(),\n",
        "        \"Avg_Phonetic_Cyrillic\": df[\"Phonetic_Cyrillic\"].mean(),\n",
        "        \"Avg_Phonetic_Arabic\": df[\"Phonetic_Arabic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Latin\": df[\"Self_BLEU_Latin\"].mean(),\n",
        "        \"Avg_Self_BLEU_Cyrillic\": df[\"Self_BLEU_Cyrillic\"].mean(),\n",
        "        \"Avg_Self_BLEU_Arabic\": df[\"Self_BLEU_Arabic\"].mean(),\n",
        "        \"Format_Accuracy\": df[\"Format_Correct\"].mean()\n",
        "    }\n",
        "\n",
        "    if keep_levenshtein:\n",
        "        avg_metrics.update({\n",
        "            \"Avg_LevenshteinDissimilarity_Latin\": df[\"LevenshteinDissimilarity_Latin\"].mean(),\n",
        "            \"Avg_LevenshteinDissimilarity_Cyrillic\": df[\"LevenshteinDissimilarity_Cyrillic\"].mean(),\n",
        "            \"Avg_LevenshteinDissimilarity_Arabic\": df[\"LevenshteinDissimilarity_Arabic\"].mean()\n",
        "        })\n",
        "\n",
        "    return df, avg_metrics\n",
        "\n",
        "\n",
        "df_results, avg_metrics = evaluate_prompt(llm, prompt_template, test_dataset, output_parser, use_cer=False, use_jaro_winkler=True, keep_levenshtein=True)\n",
        "df_results.to_csv(\"prompt_evaluation_jaro_winkler_similarity.csv\", index=False)\n",
        "print(\"Evaluation Results:\")\n",
        "print(df_results)\n",
        "print(\"\\nAverage Metrics:\")\n",
        "for k, v in avg_metrics.items():\n",
        "    print(f\"{k}: {v:.2f}\")\n"
      ],
      "metadata": {
        "id": "8aiN43QGRGZY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd12a90980564b51a34031cff92a2670": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ceb73a524744493887975fffac67d371",
              "IPY_MODEL_0237e16efcf741219f81ee989b0a9040",
              "IPY_MODEL_d01dbd62996446a487f21e13391cb5ae"
            ],
            "layout": "IPY_MODEL_28283d3e170c4e1ab3728340010aab9e"
          }
        },
        "ceb73a524744493887975fffac67d371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf865dcb4f1a4bc39131fb0986839a5b",
            "placeholder": "​",
            "style": "IPY_MODEL_bd2f630d7e52435ab1af8a218567e196",
            "value": "modules.json: 100%"
          }
        },
        "0237e16efcf741219f81ee989b0a9040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97d8da83f4184d33a6a0289d22339804",
            "max": 229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c9d542e8186447c89723dc9bcb34d154",
            "value": 229
          }
        },
        "d01dbd62996446a487f21e13391cb5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c06f8ff147d24c5996d0f84693e1a57e",
            "placeholder": "​",
            "style": "IPY_MODEL_6e640ebe5def47aab04c97efdcf5bd82",
            "value": " 229/229 [00:00&lt;00:00, 23.3kB/s]"
          }
        },
        "28283d3e170c4e1ab3728340010aab9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf865dcb4f1a4bc39131fb0986839a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd2f630d7e52435ab1af8a218567e196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97d8da83f4184d33a6a0289d22339804": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d542e8186447c89723dc9bcb34d154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c06f8ff147d24c5996d0f84693e1a57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e640ebe5def47aab04c97efdcf5bd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab7259bf9362486ba045daf398529923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23d871e7f6834e2d99c3adde8aa758fa",
              "IPY_MODEL_a5b008bfd06b45ffa6e9f3b0d0170ad3",
              "IPY_MODEL_29ccacc99f5d4f188af29a347b5de5a0"
            ],
            "layout": "IPY_MODEL_3dc674970a9c4deeb58277ecd2eb8b3b"
          }
        },
        "23d871e7f6834e2d99c3adde8aa758fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e547fd392c34381a7389ad26290df26",
            "placeholder": "​",
            "style": "IPY_MODEL_9edd682921b949ab9c27b07dd4df9380",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "a5b008bfd06b45ffa6e9f3b0d0170ad3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39d2cdcd224148e4ba7d4acc2ab34b79",
            "max": 122,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1c7a527c05f4621a3c4b439f7367d9b",
            "value": 122
          }
        },
        "29ccacc99f5d4f188af29a347b5de5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d5c93c4193644479afc4a2a24e677ab",
            "placeholder": "​",
            "style": "IPY_MODEL_ec43d09ef2824f52a024e47c406e07e2",
            "value": " 122/122 [00:00&lt;00:00, 12.7kB/s]"
          }
        },
        "3dc674970a9c4deeb58277ecd2eb8b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e547fd392c34381a7389ad26290df26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9edd682921b949ab9c27b07dd4df9380": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39d2cdcd224148e4ba7d4acc2ab34b79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1c7a527c05f4621a3c4b439f7367d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d5c93c4193644479afc4a2a24e677ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec43d09ef2824f52a024e47c406e07e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ace33074d7749358d4fb77250f88473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_39730271e29a44af8cfd588695411b93",
              "IPY_MODEL_024a9940b4304d63825c83207b67a443",
              "IPY_MODEL_966de2e698da42bb9a4d874de245f456"
            ],
            "layout": "IPY_MODEL_f19740b4d4164057a94b04b7da904dd0"
          }
        },
        "39730271e29a44af8cfd588695411b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce170ada6be4bb1a840c979310bf49d",
            "placeholder": "​",
            "style": "IPY_MODEL_1458acfa568849f9bc49d3da8399d772",
            "value": "README.md: 100%"
          }
        },
        "024a9940b4304d63825c83207b67a443": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44a647cfa23a4c13b45756a56d0f295c",
            "max": 3888,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05df1076ca4f464f8a33adbf8657cc42",
            "value": 3888
          }
        },
        "966de2e698da42bb9a4d874de245f456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e5addddea1e4d8dac37fab0cb17a0c0",
            "placeholder": "​",
            "style": "IPY_MODEL_fd04cca4cdb84fd899996acf8036e7ec",
            "value": " 3.89k/3.89k [00:00&lt;00:00, 127kB/s]"
          }
        },
        "f19740b4d4164057a94b04b7da904dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ce170ada6be4bb1a840c979310bf49d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1458acfa568849f9bc49d3da8399d772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44a647cfa23a4c13b45756a56d0f295c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05df1076ca4f464f8a33adbf8657cc42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e5addddea1e4d8dac37fab0cb17a0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd04cca4cdb84fd899996acf8036e7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48a456ef3f754dc1ac7f1b356333e9bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6dfb61fc173246b8acf683357fc0d471",
              "IPY_MODEL_b01ea239ccdb4cbcabccc4a5a7ea2678",
              "IPY_MODEL_34b99b98fc9d43f68c9e581dc749b904"
            ],
            "layout": "IPY_MODEL_41936a6b595d4c13849adb1405b3a462"
          }
        },
        "6dfb61fc173246b8acf683357fc0d471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_127976d896124873bc59add1c1d82cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_b41169c8d0ea48c5b777ff3d22b18ac2",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "b01ea239ccdb4cbcabccc4a5a7ea2678": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c857429fe34f689d6934c698491483",
            "max": 53,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74806dcd6ffe4f1fa01588d5dec4fa2a",
            "value": 53
          }
        },
        "34b99b98fc9d43f68c9e581dc749b904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2914667f1f418785c7a39a2bc45c2c",
            "placeholder": "​",
            "style": "IPY_MODEL_3321b9fdae1b44a4a259a53a2e304c30",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.07kB/s]"
          }
        },
        "41936a6b595d4c13849adb1405b3a462": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127976d896124873bc59add1c1d82cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b41169c8d0ea48c5b777ff3d22b18ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94c857429fe34f689d6934c698491483": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74806dcd6ffe4f1fa01588d5dec4fa2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf2914667f1f418785c7a39a2bc45c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3321b9fdae1b44a4a259a53a2e304c30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9369a4c958d04a05a853adca0f9de602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40823c33d69e44b39f20274cd80645cc",
              "IPY_MODEL_70e73028847244a2b373a377f2b15c88",
              "IPY_MODEL_13c00ef8f4374159beb32b1910abec5e"
            ],
            "layout": "IPY_MODEL_7cfdff1d8b5d4909b5c2b3c16926a6ed"
          }
        },
        "40823c33d69e44b39f20274cd80645cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee8ddebdc2454abf81aabd3354e59ac6",
            "placeholder": "​",
            "style": "IPY_MODEL_0193b4845adc4d1b8d1c354d48133ea9",
            "value": "config.json: 100%"
          }
        },
        "70e73028847244a2b373a377f2b15c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3c7398e37e34afb879283b16ee72a10",
            "max": 645,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9df6aab751184fb3926eff8df986e5bd",
            "value": 645
          }
        },
        "13c00ef8f4374159beb32b1910abec5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec8131b6072c4df689355d820a75ad0f",
            "placeholder": "​",
            "style": "IPY_MODEL_a84366e1ca904c438e073856a40aa535",
            "value": " 645/645 [00:00&lt;00:00, 21.1kB/s]"
          }
        },
        "7cfdff1d8b5d4909b5c2b3c16926a6ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8ddebdc2454abf81aabd3354e59ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0193b4845adc4d1b8d1c354d48133ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a3c7398e37e34afb879283b16ee72a10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9df6aab751184fb3926eff8df986e5bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec8131b6072c4df689355d820a75ad0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a84366e1ca904c438e073856a40aa535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7846981434c4a09abfa0a32e5e80b41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65e10db4a877402bbe40eae501409ad9",
              "IPY_MODEL_d00062d522c94aa5ba8d1c89ed1b11d6",
              "IPY_MODEL_d1c50eeb6e7d4d40835987117726e320"
            ],
            "layout": "IPY_MODEL_2661ecd3e01246e38cf1d36afe7592c9"
          }
        },
        "65e10db4a877402bbe40eae501409ad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa9451d63a89467b8e9649cfc703cec5",
            "placeholder": "​",
            "style": "IPY_MODEL_f8cb00e034a940419092febf6c188050",
            "value": "model.safetensors: 100%"
          }
        },
        "d00062d522c94aa5ba8d1c89ed1b11d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a29e426eef0d46b9996f19474a4c726c",
            "max": 470641600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aae9eaf97e514a54b83a47dbffde00cc",
            "value": 470641600
          }
        },
        "d1c50eeb6e7d4d40835987117726e320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ab602ce8b364095886406611860507e",
            "placeholder": "​",
            "style": "IPY_MODEL_b8dd49fb468e44cd81b4f4be55011105",
            "value": " 471M/471M [00:02&lt;00:00, 170MB/s]"
          }
        },
        "2661ecd3e01246e38cf1d36afe7592c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa9451d63a89467b8e9649cfc703cec5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8cb00e034a940419092febf6c188050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a29e426eef0d46b9996f19474a4c726c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae9eaf97e514a54b83a47dbffde00cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ab602ce8b364095886406611860507e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8dd49fb468e44cd81b4f4be55011105": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88486219b70440e88e2760a76c883824": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f565876eda0c49eaafffba3e59a06d8a",
              "IPY_MODEL_01105842233748d28ecf8dea4cc5966e",
              "IPY_MODEL_fb7fce2f01564960b764c9baded98fad"
            ],
            "layout": "IPY_MODEL_367798755ac646e7a18b722625cef24c"
          }
        },
        "f565876eda0c49eaafffba3e59a06d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed8bf2653104b718463ca22e8bdfbd1",
            "placeholder": "​",
            "style": "IPY_MODEL_496f4339992144bb820fb043f67f9e82",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "01105842233748d28ecf8dea4cc5966e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7bad08ee2fb4cc4b3ccb080659e5d08",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c7f0bffd18345b688273055b9c62840",
            "value": 480
          }
        },
        "fb7fce2f01564960b764c9baded98fad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea2cd8b473ce4d87b159d8b358da7c99",
            "placeholder": "​",
            "style": "IPY_MODEL_298b4d110a154b73b7729e14719ef7f3",
            "value": " 480/480 [00:00&lt;00:00, 12.3kB/s]"
          }
        },
        "367798755ac646e7a18b722625cef24c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed8bf2653104b718463ca22e8bdfbd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "496f4339992144bb820fb043f67f9e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7bad08ee2fb4cc4b3ccb080659e5d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7f0bffd18345b688273055b9c62840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ea2cd8b473ce4d87b159d8b358da7c99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "298b4d110a154b73b7729e14719ef7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "346448d200e44dd59d3decced75ca77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18389511a94b48d4a8f43be0109fab7c",
              "IPY_MODEL_fc36e0d966c44fd7ac9087bc036643f5",
              "IPY_MODEL_cfc3522591754ac883de381acd7242dd"
            ],
            "layout": "IPY_MODEL_cb406393f0174cffa7af28a5a168dc8d"
          }
        },
        "18389511a94b48d4a8f43be0109fab7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84463490da9740fbb53508726af5c908",
            "placeholder": "​",
            "style": "IPY_MODEL_f4fabc3a1825476790bec1e4bafcd99c",
            "value": "tokenizer.json: 100%"
          }
        },
        "fc36e0d966c44fd7ac9087bc036643f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0a11cc762c44ab4b2c780902e70f5e0",
            "max": 9081518,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_895bf3119d27467283e2499f2fc88cd3",
            "value": 9081518
          }
        },
        "cfc3522591754ac883de381acd7242dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c37da8ce8afb437eab4ff5e720f909f5",
            "placeholder": "​",
            "style": "IPY_MODEL_16a2112b60c64afd8004ada55efb45a7",
            "value": " 9.08M/9.08M [00:00&lt;00:00, 86.8MB/s]"
          }
        },
        "cb406393f0174cffa7af28a5a168dc8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84463490da9740fbb53508726af5c908": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4fabc3a1825476790bec1e4bafcd99c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0a11cc762c44ab4b2c780902e70f5e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895bf3119d27467283e2499f2fc88cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c37da8ce8afb437eab4ff5e720f909f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16a2112b60c64afd8004ada55efb45a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "998cb884774140a1807e585ee58c6919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_578806760d0447919bc044189de16424",
              "IPY_MODEL_d78732bf43944172a2d73fbbeb1a4531",
              "IPY_MODEL_e397951b8d764aa18c60db531583e673"
            ],
            "layout": "IPY_MODEL_3d19a883a5ca4c4d89892cf7ea66c7db"
          }
        },
        "578806760d0447919bc044189de16424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45cef6821ebf400f9c7e6e54a609a4f7",
            "placeholder": "​",
            "style": "IPY_MODEL_77af2770a99b48158764132327fa7452",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "d78732bf43944172a2d73fbbeb1a4531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22d228f107b2466b938c1e03d40581b3",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79ef11e1cd4943c9b969fafbe1c78b9c",
            "value": 239
          }
        },
        "e397951b8d764aa18c60db531583e673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd25ec2451f44e6f941c567ab0e067e1",
            "placeholder": "​",
            "style": "IPY_MODEL_992fa0358c9c45f4b7dd46d0b9a86994",
            "value": " 239/239 [00:00&lt;00:00, 9.63kB/s]"
          }
        },
        "3d19a883a5ca4c4d89892cf7ea66c7db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45cef6821ebf400f9c7e6e54a609a4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77af2770a99b48158764132327fa7452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d228f107b2466b938c1e03d40581b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ef11e1cd4943c9b969fafbe1c78b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd25ec2451f44e6f941c567ab0e067e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "992fa0358c9c45f4b7dd46d0b9a86994": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8a750c774c343b6ab1185e33805e30b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85d5e9287d854aed94e4cf454087e978",
              "IPY_MODEL_a11030b9a07e434cbdff64646f09fecc",
              "IPY_MODEL_fdfde3afdfb743bcab41242f88b478e7"
            ],
            "layout": "IPY_MODEL_bd56c8d5a3eb425c8887d80f089c4334"
          }
        },
        "85d5e9287d854aed94e4cf454087e978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd255845549427bb27e0edcd4a52f06",
            "placeholder": "​",
            "style": "IPY_MODEL_49924cedb298482aa0ecf4c5aed429cf",
            "value": "config.json: 100%"
          }
        },
        "a11030b9a07e434cbdff64646f09fecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c9ac8ef90a4ca1b9ae599b8b9f8aa4",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_627a747bf8a545758badc10575af64a6",
            "value": 190
          }
        },
        "fdfde3afdfb743bcab41242f88b478e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73d28ccd0989405e98e32b56f1750eb9",
            "placeholder": "​",
            "style": "IPY_MODEL_3fa423787ffa4502a91970e6edde6492",
            "value": " 190/190 [00:00&lt;00:00, 9.68kB/s]"
          }
        },
        "bd56c8d5a3eb425c8887d80f089c4334": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd255845549427bb27e0edcd4a52f06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49924cedb298482aa0ecf4c5aed429cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07c9ac8ef90a4ca1b9ae599b8b9f8aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "627a747bf8a545758badc10575af64a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73d28ccd0989405e98e32b56f1750eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fa423787ffa4502a91970e6edde6492": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}